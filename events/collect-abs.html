<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="Microsoft Word 98">
<TITLE>A-Schema McWord</TITLE>
</HEAD>
<BODY>

<B><I><FONT SIZE=5><P ALIGN="CENTER">IX Giornate di Studio del Gruppo di Fonetica Sperimentale dell'AIA</P>
<P ALIGN="CENTER"></P>
<P ALIGN="CENTER">Aspetti computazionali in fonetica, linguistica e didattica delle lingue: modelli e algoritmi</P>
</I></FONT><FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><FONT SIZE=5><P ALIGN="CENTER">Universit&agrave; Ca' Foscari &#151; Venezia</P>
<P ALIGN="CENTER">Aula Magna Ca' Dolfin</P>
<P ALIGN="CENTER">17-19 dicembre 1998</P>
</FONT><FONT SIZE=4><P ALIGN="CENTER">&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;&#176;</P>
</FONT><FONT FACE="Helvetica" SIZE=5><P ALIGN="CENTER">PRIMA GIORNATA</P>
</FONT><FONT SIZE=4><P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">9.15    Apertura Convegno</P>
<P ALIGN="JUSTIFY">9.30</P>
<P ALIGN="JUSTIFY">Luciano Nebbia, Silvia Quazza, Pier Luigi Salza</P>
</B></FONT><P ALIGN="JUSTIFY">Una tecnica di sintesi vocale specializzata per il dominio lessicale dell&#146;Elenco Abbonati</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">10.00 </P>
<P ALIGN="JUSTIFY">Fabrizio Balducci, Loredana Cerrato, Domenico D&#146;Alterio</P>
</B></FONT><P>Valutazione delle prestazioni di un segmentatore per l&#146;italiano</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">10.30</P>
<P ALIGN="JUSTIFY">Emanuela Magno Caldognetto, Claudio Zmarich</P>
</B></FONT><P ALIGN="JUSTIFY">Implicazioni linguistiche e psicolinguistiche delle ricerche fonetiche sulle &quot;facce parlanti&quot;</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">11.00   Pausa</P>
<P ALIGN="JUSTIFY">11.30</B> </P>
<B><P ALIGN="JUSTIFY">Anna Zanfei &amp; Cesare Gagliardi &amp; Luca Stefanutti</P>
</B></FONT><P>Algoritmi di assessment per un percorso di apprendimento personalizzato: il self-access per L2.</P>
<FONT FACE="Courier New" SIZE=2><P>&nbsp;</P>
</FONT><B><FONT SIZE=4><P ALIGN="JUSTIFY">12.00 </P>
<P ALIGN="JUSTIFY">Dario Bianchi, Enrico Baricchi, Giovanni Adorni </P>
</B></FONT><P ALIGN="JUSTIFY">Automated Learning of Acoustic Indexes from Data in a Text-to-Speech System for Italian</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">12.30   Pausa pranzo</P>
<P ALIGN="JUSTIFY">14.30</P>
</FONT><FONT FACE="Times New Roman,Times New Roman" SIZE=4><P ALIGN="JUSTIFY">Emanuela Cresti, Philippe Martin, Massimo Moneglia</P>
</B></FONT><P ALIGN="JUSTIFY">Intonazione delle modalit&agrave; naturali rappresentative: analisi e sintesi </P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">15.00</P>
<P ALIGN="JUSTIFY">Renata Savy </P>
</B></FONT><P ALIGN="JUSTIFY">Su alcuni rapporti tra riduzione segmentale e struttura soprasegmentale nel parlato spontaneo.</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">15.30</P>
<P ALIGN="JUSTIFY">Antonella Giannini e Massimo Pettorino</P>
</B></FONT><P ALIGN="JUSTIFY">I cambiamenti dell&#146;italiano radiofonico negli ultimi 50 anni</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">16.15   Pausa</P>
</B><P ALIGN="JUSTIFY">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</P>
<P ALIGN="JUSTIFY"></P>
</FONT><B><FONT FACE="Helvetica" SIZE=5><P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">SECONDA GIORNATA</P>
</B></FONT><FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><B><FONT SIZE=5><P ALIGN="CENTER">Tavola Rotonda</P>
</B></FONT><FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><B><I><FONT SIZE=5><P ALIGN="CENTER">Aspetti Quantitativi vs. Aspetti Qualitativi dell'Analisi Fonetico-Acustica</P>
</B></I></FONT><FONT SIZE=4><P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;                        </P>
<P ALIGN="JUSTIFY">Il riconoscimento e la sintesi del parlato sono divenute tecnologie importanti nella vita quotidiana della societ&agrave; contemporanea. Sono fondate sulla raccolta e analisi di enormi quantit&agrave; di dati linguistici. Le basi di dati sono quindi utilizzate per costruire modelli predittivi che funzionano in modo probabilistico nelle applicazioni reali.</P>
<P ALIGN="JUSTIFY">Attualmente sia il riconoscimento sia la sintesi sono ben lungi dal costituire dei prodotti finiti, ma anche se imperfetti vengono comunque commercializzati. Sino a che punto lo studio della variabilit&agrave; linguistica interindividuale e intraindividuale pu&ograve; contribuire a perfezionare le tecniche di messa a</P>
<P ALIGN="JUSTIFY">punto dei modelli, considerato che le lingue naturali contengono indubbie regolarit&agrave; sistematiche a vari livelli di rappresentazione astratta, in particolare di tipo sovrasegmentale e superiore al livello di parola??</P>
<P ALIGN="JUSTIFY">&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;&#167;</P>
<P ALIGN="JUSTIFY"></P>
<B><P ALIGN="CENTER">Moderatore: John Trumper</P>
</B><P ALIGN="JUSTIFY"></P>
<B><P>9.00 </P>
</B></FONT><P ALIGN="JUSTIFY">FUB-L.Cerrato: La modellizzazione della variazione di pronuncia riesce a migliorare le prestazioni dei riconoscitori automatici?</P>
<P>Scuola Normale-B.Gili: Modelli di predizione prosodica</P>
<P>CSELT-G.Micca: Riconoscimento multilingue con modellamento delle transizioni</P>
<P>IRST-M.Omologo: Gli HMMs nel riconoscimento all'IRST</P>

<B><FONT SIZE=4><P>10.00  Discussione</P>
<P ALIGN="JUSTIFY">10.30   Pausa</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">11.00</B> </P>
</FONT><P>C.Avesani: Intonazione e modelli linguistici</P>
<P>F.Albano-Leoni: Variabilita' nella realizzazione individuale</P>
<P>E.Caldognetto: La realizzazione delle emozioni</P>
<P>R.Delmonte: Variabilit&agrave; Prosodica e Modelli Multilinguistici</P>
<P>S.Canazza-A.Vidolin: Il modello di resa delle intenzioni espressive nell'esecuzione musicale/vocale mediante analisi-sintesi del Centro di Sonologia Computazionale di Padova</P>

<B><FONT SIZE=4><P>12.15  Discussione</P>
<P ALIGN="JUSTIFY">13.00   Pausa pranzo</P>
<P ALIGN="JUSTIFY">14.30</P>
</B></FONT><FONT FACE="Helvetica" SIZE=4><P ALIGN="JUSTIFY">PRESENTAZIONE A  INVITO</P>
</FONT><P>Piero Cosi</P>
<FONT FACE="Helvetica" SIZE=4><P>OGI Toolkit.: Il riconoscimento automatico del linguaggio naturale alla portata di tutti.</P>

</FONT><B><FONT SIZE=4><P>15.15  Discussione</P>
<P ALIGN="JUSTIFY">15.30 Posters</P>
<P ALIGN="JUSTIFY">Bacalu-Delmonte</B>, </FONT>Prosodic Modeling for Syllable Structures from the VESD - Venice English Syllable Database</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">Bistrot-Delmonte</B>, </FONT>Il MUSEIKA in giapponese: desonorizzazione, devocalizzazione o elisione vocalica?</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">Delogu-Aiello-Di Carlo-Nisi-Tummeacciu</B>, </FONT>Valutazione di corpora generati a partire da scenari testuale e visivi</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">Zanfei-Gagliardi</B></FONT><FONT FACE="Courier New" SIZE=2>, </FONT>Progetto per la sperimentazione di un tutor computerizzato per l'apprendimento della prosodia dell'inglese per  italofoni: il modulo prosodico dello SLIM di Venezia</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">16.30   Pausa</P>
<P ALIGN="JUSTIFY">17.00   </B>Assemblea del Gruppo di Fonetica Sperimentale (GFS).</P>
<B><P ALIGN="JUSTIFY">17.30</B>   Assemblea del Centro InterUniversitario di Fonetica (CIUF).</P>
<B><P ALIGN="JUSTIFY">18.00</B>   Partenza per Burano</P>
<B><P ALIGN="JUSTIFY">20.00</B>   Cena Sociale</P>
<P ALIGN="JUSTIFY">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
</FONT><B><FONT FACE="Helvetica" SIZE=5><P ALIGN="CENTER">ULTIMA GIORNATA</P>
</FONT><FONT SIZE=4><P ALIGN="JUSTIFY">9.30</P>
<P ALIGN="JUSTIFY">Antonio Romano &amp; Stefania Roullet</P>
</B></FONT><P ALIGN="JUSTIFY">Brevi osservazioni in merito ad alcune differenze tra gli schemi intonativi adottati da uno stesso locutore per comunicare in codici linguistici diversi</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">10.00 </P>
<P ALIGN="JUSTIFY">Carlo Schirru</P>
</B></FONT><P ALIGN="JUSTIFY">Verso un dimensionamento consonantico-temporale dell'italiano sardo-campidanese.</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">10.30</P>
<P ALIGN="JUSTIFY">Claudio Zmarich</P>
</B></FONT><P>Dinamiche articolatorie nella produzione verbale fluente di normoparlanti e balbuzienti</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">11.00   Pausa</P>
<P ALIGN="JUSTIFY">11.30</B> </P>
<B><P ALIGN="JUSTIFY">Francesco Cutugno </P>
</B><P ALIGN="JUSTIFY">Il tempo della voce. </P>
<B><P ALIGN="JUSTIFY">12.00 </P>
<P>Reiko ENDO, Pier Marco BERTINETTO</P>
</B></FONT><P ALIGN="JUSTIFY">Caratteristiche prosodiche delle cos&igrave; dette consonanti &quot;rafforzate&quot; dell&#146;italiano</P>
<B><FONT SIZE=4><P ALIGN="JUSTIFY">12.30</B>   Chiusura dei lavori</P>
<P ALIGN="RIGHT"></P>
<P ALIGN="RIGHT">&nbsp;</P>
<P ALIGN="RIGHT">&nbsp;</P>
<P ALIGN="RIGHT">&nbsp;</P>
<P ALIGN="RIGHT">&nbsp;</P>
</FONT><B><FONT FACE="Vivaldi" SIZE=7><P ALIGN="CENTER">R</FONT><I><FONT FACE="MosiacFixed" SIZE=7>IASSUNTI</P>
</B></I></FONT><FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><FONT SIZE=5><P ALIGN="CENTER">ELENCO AUTORI</P>
</FONT><FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><B><FONT FACE="Courier New" SIZE=4><P>- Albano Leoni</P>
<P>- Bacalu-Delmonte</P>
<P>- Bertinetto-Endo</P>
<P>- Bianchi-Baricchi-Adorni</P>

<UL>
<LI>Bistrot-Delmonte</LI>
<LI>Caldognetto</LI>
<LI>Caldognetto-Zmarich</LI>
<LI>Canazza</LI></UL>

<P>- Cerrato-Balducci-D&#146;Alterio</P>
<P>- Cosi</P>
<P>- Cresti-Martin-Moneglia</P>

<UL>
<LI>Cutugno</LI>
<LI>Delmonte</LI>
<LI>Falcone</LI></UL>

<P>- Gagliardi-Zanfei-Stefanutti</P>

<UL>
<LI>Giannini</LI>
<LI>Gili</LI>
<LI>Micca</LI>
<LI>Omologo</LI></UL>

<P>- Pettorino</P>
<P>- Romano-Roullet</P>
<P>- Salza-Nebbia-Quazza</P>
<P>- Savy</P>
<P>- Schirru</P>
<P>- Zanfei-Gagliardi</P>
<P>- Zmarich</P>
</B></FONT><FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><FONT SIZE=5><P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">La Variabilit&agrave; nella Realizzazione Individuale</P>
<P ALIGN="CENTER"></P>
</FONT><I><P ALIGN="CENTER">Federico Albano Leoni</P>
</I><P ALIGN="CENTER">CIRASS - Universit&agrave; di Napoli "Federico II"</P>
<P ALIGN="CENTER">v. Porta di Massa 1</P>
<P ALIGN="CENTER">I-80133 Napoli</P>
<P ALIGN="CENTER">tel. +39 81 5420280</P>
<P ALIGN="CENTER">fax +39 81 5420370</P>
<P ALIGN="CENTER">e-mail:<A HREF="mailto:cutugno@unina.it"> fealbano@unina.it </A></P>
<FONT SIZE=4><P ALIGN="CENTER"></FONT><A HREF="http://www.unina.it/cirass"><U><FONT SIZE=4 COLOR="#0000ff">http://www.unina.it/cirass</U></FONT></A></P>
<P ALIGN="CENTER"></P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="JUSTIFY">La variabilit&agrave; &egrave; un caratteristica intrinseca di tutte le lingue storico-naturali e si manifesta, come noto, sui piani diacronico, diatopico, diastratico, diafasico e diamesico, ai quali va aggiunto quello idiosincratico individuale. Tale caratteristica &egrave; particolarmente evidente sul piano fonico.</P>
<P ALIGN="JUSTIFY">Se si conviene su questa valutazione, ne consegue che un&#146;analisi fonetica che sia attenta tanto ai modelli fonologici, quanto alle applicazioni pratiche, deve affiancare all&#146;analisi qualitativa anche l&#146;analisi quantitativa dei fenomeni, osservati all&#146;interno di corpora di parlato che riflettano la naturale stratificazione di ciascuna lingua, dei parlanti e dei loro comportamenti comunicativi. L&#146;analisi quantitativa consente di individuare non regole, la cui efficacia &egrave; a volte opinabile, ma tendenze associate a probabilit&agrave;.</P>
<P ALIGN="JUSTIFY">L&#146;esigenza di disporre di corpora ampi e stratificati &egrave; particolarmente viva nell&#146;ambito degli studi su intonazione e ritmo, che sempre di pi&ugrave; si rivelano di una importanza cruciale per la comprensione e la descrizione della comunicazione parlata e per i quali le conoscenze accumulate sono ancora insufficienti. La variabilit&agrave; del ritmo e dell&#146;intonazione hanno infatti uno statuto diverso da quello della variabilit&agrave; segmentale: infatti, mentre quest&#146;ultima &egrave; in gran parte meccanica, la prima &egrave; invece associata a una grande variet&agrave; di intenzioni semantico-pragmatiche del parlante.</P>
<FONT SIZE=5><P ALIGN="CENTER"></P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">Prosodic Modeling for Syllable Structures from the VESD - Venice English Syllable Database</P>
</FONT><B><FONT SIZE=4><P ALIGN="CENTER">Ciprian Bacalu, Rodolfo Delmonte</P>
</B></FONT><FONT SIZE=2><P ALIGN="CENTER">Laboratory of Computational Linguistics</P>
<P ALIGN="CENTER">Section of Linguistics</P>
<P ALIGN="CENTER">Ca&#146; Garzoni-Moro, San Marco 3417</P>
<P ALIGN="CENTER">Universit&agrave; Ca&#146; Foscari &#151; 30124 VENEZIA</P>
<P ALIGN="CENTER">E-mail: </FONT><A HREF="mailto:bacalu@unive.it"><U><FONT SIZE=4 COLOR="#0000ff">bacalu@unive.it</U></FONT></A></P>
<FONT SIZE=2><P ALIGN="CENTER">WWW:- </FONT><A HREF="http://byron.cgm.unive.it/"><U><FONT SIZE=4 COLOR="#0000ff">http://byron.cgm.unive.it</U></FONT></A></P>
<FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><FONT SIZE=3><P ALIGN="JUSTIFY">The VESD has been created in order to be used in the Prosodic Module of SLIM &#151; an acronym for Multimedia Interactive Linguistic Software, developed at the University of Venice. The Prosodic Module is composed of learning activities dealing with phonetic and prosodic problems at word segmental level and at utterance suprasegmental level. The main goal of this module is that of improving student&#146;s performance both in the perception and production of prosodic aspects of spoken language activities. The information stored in the syllable database is used both to improve the performance of the automatic segmentation of the speech signal and to give a better feedback to the student, to tell him where or what the mistake is. Preliminary investigation has also been carried out on how the syllable database can be used to build a speech recognition system that uses syllable-like units instead of phoneme-like ones as the building blocks for the recognition process.</P>
<P ALIGN="JUSTIFY">Usually read speech databases contain hand-annotated time-aligned phoneme-level and word-level transcriptions of each utterance. Our attempt was to use the information available in order to build a syllable-level transcription of each utterance. Using only phoneme-level information was found to be difficult because the continuous syllable parsing is not as simple at utterance-level as it is at word-level. So both phoneme-level and word-level time-aligned transcriptions have been used. In order to build a database that contains syllable-level information along with word-level and phoneme-level information we used the WSJCAM0 - the Cambridge version of the continuous speech recognition corpus produced from the Wall Street Journal, </FONT>distributed by the Linguistic Data Consortium (LDC). We worked on a subset of 4165 sentences, with 70,694 words which constitute half of the total number of words in the corpus amounting to 133,080. We ended up with 113,282 syllables and 287,734 phones. The final typology is made up of 44 phones, 4393 syllable types and 11,712 word types. As far as syllables are concerned, we considered only 3409 types. </P>
<FONT SIZE=3><P ALIGN="JUSTIFY">In order to build syllable structures we tried to develop an automatic procedure. The algorithm for word-level syllable parsing that we used is based on the structure of English syllables and on some phonological rules. The syllable is made of a <I>nucleus</I><B>,</B> which is a vowel or a vowel-like consonant &#151; usually a sonorant, that can be optionally prefixed and suffixed by a number of consonants, termed the <I>onset</I> and <I>coda</I> respectively. A LALR(1) grammar has been written based on this syllable structure and on the phoneme-level structure of the <I>onset</I>, <I>nucleus</I> and <I>coda</I>. We found this grammar useful for dividing the syllable into <I>onset</I>, <I>nucleus</I> and <I>coda</I>, but modifying the grammar to parse sequences of syllables resulted in an ambiguous grammar. Some phonological rules have to be applied and more look-ahead has to be done in order to resolve the conflicts during the parsing process. Based on these considerations a modified finite state automata has been built in order to parse words as sequences of syllables. The algorithm has been tested first using the Carnegie Mellon University Pronouncing Dictionary that contains more than 100.000 entries. The errors made by the algorithm were found to be caused mainly by foreign and by compound words. To limit such kind of errors we organized a list of the most frequently used foreign and compound words already divided into syllables and asked the parser to search this list every time a new segmentation is tried at word level.</P>
<P ALIGN="JUSTIFY">Using the syllable-parsing algorithm the time-aligned syllable-level transcription of each utterance has been obtained. Then a relational database containing phrases, words, syllables and phonemes has been created. Stress information has also been included into the syllable database. This latter information has resulted from the subdivision of words into function and content words.</P>
</FONT><B><I><FONT SIZE=4><P ALIGN="JUSTIFY">Bibliography</P>
</B></I></FONT><FONT FACE="Garamond,Times New Roman" SIZE=3><P ALIGN="JUSTIFY">Delmonte R., M.Petrea, C.Bacalu (1997), <I>SLIM Prosodic Module for Learning Activities in a Foreign Language</I>, Proc.ESCA, Eurospeech97, Rhodes, Vol.2, pp.669-672.</P>
<P ALIGN="JUSTIFY">Selkirk, E. (1982), &quot;<I>The syllable</I>&quot;, <I>The Structure of Phonological Representations</I>, volume II, ed. by H. van der Hulst and N. Smith, Dordrecht: Foris, 337-383.</P>
<P ALIGN="JUSTIFY">Kahn, D. (1976), <I>Syllable-based Generalizations in English Phonology</I>, MIT doctoral dissertation, distributed by IULC.</P>
<P ALIGN="JUSTIFY">Hammond Michael (1995), <I>Syllable parsing in English and French</I>, University of Arizona, draft: May 25, 1995</P>
</FONT><FONT SIZE=5><P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">Caratteristiche prosodiche delle cos&igrave; dette</P>
<P ALIGN="CENTER">consonanti &quot;rafforzate&quot; dell&#146;italiano</P>
</FONT><FONT SIZE=4><P ALIGN="CENTER">Reiko ENDO</P>
<P ALIGN="CENTER">Pier Marco BERTINETTO</P>
</FONT><P ALIGN="CENTER">La corrispondenza pu&ograve; essere indirizzata al secondo autore presso:</P>
<P ALIGN="CENTER">Scuola Normale Superiore</P>
<P ALIGN="CENTER">p.zza dei Cavalieri 7</P>
<P ALIGN="CENTER">56126 Pisa</P>
<P ALIGN="CENTER">email: <A HREF="mailto:bertiNET@sns.it"><U><FONT COLOR="#0000ff">bertiNET@sns.it</U></FONT></A></P>
<P ALIGN="CENTER"></P>
<P ALIGN="JUSTIFY">1.<FONT SIZE=4>&#9;</FONT>Nella fonetica e fonologia dell&#146;italiano vengono convenzionalmente designate come &quot;rafforzate&quot; le consonanti palatali (/S L N/) nonch&eacute; tutte le affricate (tS dZ ts dz/), indipendentemente dal loro punto di articolazione.* Con ci&ograve; si allude al fatto che, nella pronuncia dello standard (e delle variet&agrave; centro-meridionali in generale), le palatali intervocaliche e le affricate possiedono una durata maggiore rispetto alle normali consonanti scempie. Di questo fatto si tiene conto anche nella sillabazione, dove tali consonanti sono considerate alla stregua di geminate, fatta ovviamente salva la posizione iniziale assoluta. Questo trattamento viene mantenuto, per coerenza sistemica, anche nel caso di pronunce chiaramente non rafforzate, come quelle delle affricate palatali del toscano, sottoposte ad un nettissimo processo di fricativizzazione (cf. la pronuncia toscana di <I>cacio</I> e <I>adagio</I>; ma lo stesso vale, limitatamente alla sorda, per molte variet&agrave; centro-meridionali). Per converso, si assume comunemente che nelle variet&agrave; settentrionali non si abbia il rafforzamento delle palatali e delle affricate, e che per queste ultime, in particolare, sussista la correlazione di quantit&agrave; (cf. l&#146;opposizione in <I>bacio</I> vs. <I>laccio</I> nell&#146;italiano settentrionale).</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">2.&#9;Scopo del lavoro che si intende presentare &egrave; la verifica di questo sapere tradizionale, condotta su tre piccoli gruppi di parlanti di diversa provenienza: 5 piemontesi, 6 pisani, 5 napoletani. Oltre alle consonanti rafforzate, &egrave; stato preso in considerazione, a titolo di opportuno raffronto, un campione di consonanti scempie e geminate: /n n: l l: z s s: t t: d d:/.Per mantenere il pi&ugrave; possibile costanti le condizioni prosodiche generali, tutte le consonanti bersaglio sono state studiate all&#146;interno di verbi, ciascuno dei quali &egrave; stato inserito in tre frasi di senso compiuto, concepite in maniera tale da mantenere inalterate le distanze interaccentuali ed il numero di sillabe complessivo (controbilanciando opportunamente la diversa estensione sillabica dei verbi utilizzati). I verbi impiegati erano i seguenti: ba<B>gn</B>are, sba<B>gli</B>are, fa<B>sci</B>are, ringra<B>z</B>iare, sgua<B>zz</B>are, organi<B>zz</B>are, sta<B>n</B>are, appa<B>nn</B>are,peda<B>l</B>are, traba<B>ll</B>are, inta<B>s</B>are, abba<B>ss</B>are, ba<B>ci</B>are, ghia<B>cci</B>are, ada<B>gi</B>are,assa<B>ggi</B>are, dila<B>t</B>are, alla<B>tt</B>are, arre<B>d</B>are, raffre<B>dd</B>are. </P>
<P ALIGN="JUSTIFY">&#9;Ogni soggetto ha letto tre volte l&#146;intero corpus. Le misurazioni hanno riguardato la durata delle consonanti bersaglio nonch&eacute;- per controllare l&#146;eventuale effetto accorciante di queste ultime -la durata delle vocali immediatamente precedenti. Si riportano qui in forma molto succinta i risultati, che saranno debitamente illustrati mediante apposite tabelle nella presentazione orale. Si pu&ograve; comunque anticipare che tali risultati hanno riservato alcune significative sorprese, che scardinano in parte le idee ricevute.</P>
<FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><P ALIGN="JUSTIFY">3.<FONT SIZE=4>&#9;</FONT>Innanzi tutto, i contrasti di durata tra le vocali che precedono le scempie e le geminate non sono risultati altrettanto netti in tutti i casi. Essi lo sono stati per le ostruenti (/d ~ d:/, /t ~ t:/, /s ~ s:/), ma non per le sonoranti (/n ~ n:/, /l ~ l:/). Quanto ai singoli foni rafforzati:</P>
<FONT SIZE=4><P ALIGN="JUSTIFY">- </FONT><I>Sonoranti palatali</I> /N L/:</P>
<P ALIGN="JUSTIFY">(a) Non si &egrave; riscontrata alcuna tendenza ad accorciare la vocale precedente; va peraltro osservato che, nella circostanza considerata,questo parametro non &egrave; informativo, poich&eacute; nel nostro corpus &#151; come detto - l'opposizione di durata &egrave; risultata assente proprio nei casi che avrebbero dovuto fornire il metodo di paragone (ossia, nelle sonoranti dentali). </P>
<P ALIGN="JUSTIFY">(b) Circa la durata di /N L/, si &egrave; constatata una sostanziale omogeneit&agrave; tra i nostri locutori. Nonostante la maggior complessit&agrave; articolatoria, i due foni considerati non raggiungono mai la durata dei corrispondenti foni dentali geminati /n: l:/. Ci&ograve; porta a concludere che le sonoranti palatali dell'italiano non manifestano, indipendentemente dalla variet&agrave; considerata, propriet&agrave; tali da imporle come autentici foni 'rafforzati'. </P>
<P ALIGN="JUSTIFY">- <I>Fricativa palatale</I> /S/:</P>
<P ALIGN="JUSTIFY">(a) Nella pronuncia dei locutori centro-meridionali, /S/ si presenta decisamente rafforzato. </P>
<P ALIGN="JUSTIFY">(b) La situazione dei piemontesi &egrave; pi&ugrave; incerta. La durata della consonante &egrave; intermedia rispetto a /s/ e /s:/, mentre la durata della vocale precedente colloca /S/ sullo stesso piano di /s:/ (vedi sotto per ulteriori considerazioni al riguardo).  </P>
<P ALIGN="JUSTIFY">- <I>Affricata palatale sorda</I> /tS/:</P>
<P ALIGN="JUSTIFY">(a) Il contrasto di durata tra affricata palatale sorda ortograficamente scempia vs. geminata (cf. <I>baciare</I> vs.<I>ghiacciare</I>) &egrave; ovunque nettissimo: il fono ortograficamente scempio non presenta iconnotati autentici di un fono rafforzato, n&eacute; coi locutori centro-meridionali (che lo deaffricatizzano), n&eacute; coi piemontesi (che ne mantengono inalterate le propriet&agrave; articolatorie).</P>
<P ALIGN="JUSTIFY">(b) Nulla di sistematico si pu&ograve; invece asserire in merito alla durata delle vocali.</P>
<P ALIGN="JUSTIFY">- <I>Affricata palatale sonora</I> /dZ/:</P>
<P ALIGN="JUSTIFY">(a) Coi locutori pisani e piemontesi, la situazione &egrave; identica a quella appena descritta per il corrispondente fono sordo, con l'aggiunta che, in questo caso, l'opposizione tra fono ortograficamente scempio vs. geminato &egrave; suffragata anche dalla differenza di durata vocalica. </P>
<P ALIGN="JUSTIFY">(b) Coi napoletani, abbiamo un quadro pi&ugrave; articolato. Rispetto alla durata consonantica, i due foni (ortograficamente scempio e geminato) sono esattamente equivalenti, mentre emerge un netto contrasto di durata vocalica (vedi sotto per ulteriori considerazioni). </P>
<P ALIGN="JUSTIFY">- <I>Affricate dentali</I>  /ts dz/:</P>
<P ALIGN="JUSTIFY">(a) Si osserva una differenza di durata tra la sorda e la sonora ortograficamente geminate, da attribuirsi evidentemente alle diverse propriet&agrave; articolatorie;</P>
<P ALIGN="JUSTIFY">(b) Non si osserva invece alcun contrasto nella durata delle due varianti sorde (ortograficamente scempia vs. geminata), e ci&ograve; non solo per iparlanti centro-meridionali, ma anche per i piemontesi. </P>
<P ALIGN="JUSTIFY">(c) Bench&eacute; i dati relativi alle vocali non siano utilizzabili in questo caso, per la non perfetta confrontabilit&agrave; dei foni vocalici presenti in questa parte nel nostro corpus, ci sembra corretto suggerire che le affricate dentali siano omogeneamente rafforzate in tutte le variet&agrave; considerate. </P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">4.&#9;Per concludere, ci limiteremo qui a sottolineare i due punti seguenti. </P>
<P ALIGN="JUSTIFY">&#9;Il sussistere di contrasti di durata vocalica in assenza di analoghi contrasti tra le durate dei foni consonantici bersaglio (un evento osservato in pi&ugrave; d&#146;una delle circostanze sopra descritte), ci pone di fronte ad un dilemma. La differenza di durata vocalica indurrebbe ad es. ad attribuire rilevanza fonologica, coi locutori napoletani, all'opposizione tra l'affricata palatale sonora /dZ/ortograficamente scempia e la corrispondente geminata, bench&eacute; la durata media di questi due foni sia praticamente identica. Ma ci&ograve; rappresenterebbe un fatto piuttosto anomalo, visto che in italiano le differenze di durata vocalica (fonologicamente condizionate) possono risultare davvero significative solo quando si sommino a concomitanti differenze di durata consonantica, mentre non possono mai esserlo di per s&eacute; sole.</P>
<P ALIGN="JUSTIFY">&#9;Si deve inoltre, e soprattutto, rilevare che in nessuna delle variet&agrave; considerate i foni presunti rafforzati si comportano come un insieme omogeneo. Alcuni di essi manifestano le propriet&agrave; di autentiche rafforzate; gli altri no, o comunque non in maniera tale da suggerirne un'interpretazione netta. La contrapposizione tradizionale tra pronunce settentrionali e centro-meridionali appare, alla luce dei risultati ottenuti, come la grossolana semplificazione di una realt&agrave; molto pi&ugrave; complessa e sfumata, indubbiamente meritevole di ulteriori e pi&ugrave; sistematiche indagini.</P>
<FONT SIZE=4><P ALIGN="JUSTIFY"></P>

<UL>
</FONT><P ALIGN="JUSTIFY"><LI>Per scongiurare errori dovuti a difficolt&agrave; di trasmissione via rete, si adopera qui una trascrizione semplificata ispirata al sistema SAMPA, in cui le maiuscole stanno ad indicare suoni palatali: /S/ = fricativa palatale sorda, /Z/ = fricativa palatale sonora, /L/ = laterale palatale, /N/ = nasale palatale.</LI></P></UL>

<P ALIGN="JUSTIFY"></P>
<B><FONT SIZE=5><P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">Automated Learning of Acoustic Indexes from Data in a Text-to-Speech System for Italian</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER"></P>
<P ALIGN="CENTER">Dario Bianchi &#151; Enrico Baricchi &#151; Giovanni Adorni</P>
<P ALIGN="CENTER">Dipartimento di Ingegneria dell&#146;Informazione Universit&agrave; di Parma</P>
<P ALIGN="CENTER"></P>
</I><B><P ALIGN="CENTER">Contact author: </B>Dario Bianchi</P>
<I><P ALIGN="CENTER">Dipartimento di Ingegneria dell&#146;Informazione Universit&agrave; di Parma</P>
<P ALIGN="CENTER">Viale delle Scienze - 43100 Parma, Italy</P>
<P ALIGN="CENTER">phone: +39 521 905725, fax: +39 521 905723,</P>
</I><P ALIGN="CENTER">email: </FONT><A HREF="mailto:bianchi@ce.unipr.it"><I><U><FONT COLOR="#0000ff">bianchi@ce.unipr.it</I></U></FONT></A></P>
<FONT SIZE=4><P ALIGN="CENTER"></P>
</FONT><P ALIGN="JUSTIFY">We are developing a text-to-speech system for Italian which uses a formant synthesizer to produce vocal output. To obtain a good quality with formant synthesizer, the main problem is the tuning of the parameters  (frequency, amplitude, bandwidth of formants, source parameters etc). The number of parameters is very high and it is very important to study the transition zone between a sound and the following one (the coarticulation process). </P>
<P ALIGN="JUSTIFY">In this paper we present a technique based on genetic algorithms to optimize the synthesizer parameters by comparing the natural speech  signal (obtained by recording the utterance of a human speaker) and a synthetically produced signal. This technique simplifies and speeds up the process of tuning the synthesizer. </P>
<P ALIGN="JUSTIFY">A well known synthesizer is that proposed by Klatt where both cascade and parallel architecture were used, the former simulates the poles of the vocal tract transfer function and is used to produce vowels while the latter is used to produce the fricative sounds. The high number of parameters used (39) to control the system can reconstruct any human speech sound with a good output quality. This synthesizer has been extensively studied and used for English language but no specific data are available for the parameters needed to generate Italian phonemes with the Klatt synthesizer.</P>
<P ALIGN="JUSTIFY">In order to simplify the process of parameter optimization, we have used a simpler model which uses only 19 control parameters but retains a good output quality.  The cascade part of the vocal tract model may be simulated by the parallel resonators configuration if suitable values are chosen for the amplitude controls. So we have removed the cascade resonators. Five resonators, connected in a parallel, are needed to simulate the poles of the vocal tract transfer function. Each resonator has associated a frequency F, a bandwidth B and an amplitude control A.  A voicing source gives a periodic signal of amplitude AV at the fundamental frequency F0. A noise source is used for frication and is controlled by the amplitude parameter AF. For voiced fricatives both the periodic and the noise source are used.  To optimize the synthesizer parameters we have used a genetic algorithm which learn the parameters from trails of recorded natural speech. A chromosome represents the set of parameters we want to optimize. In a genetic algorithm we have to define a fitness function which is used to apply a selective pressure to the population. In speech processing  the audio signal may be considered almost constant on  a time of the order of 5-10 ms. So we have broken the audio recording in frames of 8 ms of duration. </P>
<P ALIGN="JUSTIFY">Each recorded frame is compared with a frame of identical duration produced by the synthesizer. This comparison should be in agreement with the recognition based on the human perception. Comparing signals in the time domain does not meet this criterion. Actually, different spectral region have different weight in the phoneme discrimination process (some spectral region are characteristic the phoneme and others of the speaker). Also the fundamental frequencies of the signal may change and the phases are arbitrary. The comparison is performed better on the spectral properties i.e. in the frequency domain.</P>
<P ALIGN="JUSTIFY">To evaluate the fitness for a single frame the following steps are considered:</P>
<OL TYPE="a">

<P ALIGN="JUSTIFY"><LI>a low pass filter is applied to the recorded signal (the target)  to eliminate high frequency (up to 3 kHz for vowels and to 5 kHz for the other sounds) </LI></P>
<P ALIGN="JUSTIFY"><LI> using the parameters coded in the chromosome the signal is synthesized for the same time duration and with the same sampling rate of the target</LI></P>
<P ALIGN="JUSTIFY"><LI>a windowing is applied to the target and synthetic signal (with square or gaussian shape)</LI></P>
<P ALIGN="JUSTIFY"><LI>a 128 points Fast Fourier Transform is applied to both data </LI></P>
<P ALIGN="JUSTIFY"><LI>the fitness function is obtained comparing the Fourier spectra of the target and of the synthetic signal, using an euclidean distance between the two Fourier component vectors.</LI></P></OL>

<P ALIGN="JUSTIFY">So for each frame the optimization process gives the synthesizer parameters corresponding to a single sound. The process is repeated for all the frames of the recorded wave.</P>
<P ALIGN="JUSTIFY">For vowels it is necessary to optimize the frequency and the bandwidth of the first three formants. The 4<SUP>th</SUP> and 5<SUP>th</SUP> formants give the talker characteristic and don&#146;t affect the intelligibility of synthesis. They are related with some spectral details rather then perceptive features and so were not optimized. Also the amplitudes of the first 3 formants can be held constant.  Fricative unvoiced source can be generated using the noise source and the high frequency resonators.  The fricative amplitude AF and frequency, bandwidth and amplitude of third, fourth end fifth formants were optimized. The first and second resonators are not used. For voiced fricative there are two active source of sound, one located at the glottis (voicing) and one at the constriction of the vocal tract (friction). So the voicing and frication amplitudes (AV and AF) should be included in the number of parameters to optimize. The same parameters are used for sonorants </P>
<P ALIGN="JUSTIFY">For nasals, a nasal pole and a nasal zero with fixed parameters were added to the system. Only the voicing source is used. Plosives are very short in time and distributes energy on all the five formants. High frequency amplitude A4 and A5 are also used. </P>
<P ALIGN="JUSTIFY">The easier case for the GA is that of vowels, in which only 6 parameters are used and a convergence can be usually obtained with a population of 70 individuals and 3000 generations. By the other hand voiced fricatives and plosives require the highest number of parameters (13) and a higher number of generations is required to obtain a good result (typically 15000). A convergence to a good fit was reached for all the frames in the recordings test set. The GA can be runned independently for each frame starting with a new random population every time. Nevertheless we can take advantage from the fact that in the speech signal the formants frequencies, amplitudes and bandwidth vary with continuity as a function of time. So an elithistic method was used. From one frame optimization to the next a small fraction of the final population was maintained. Typically, using a population of 70 chromosomes, the 10 best individuals obtained at the end of the optimization are transferred into the initial population used for the optimization of the next frame (while the remaining 60 individuals were initialized randomly). This method result in a shortest time required to obtain convergence and in a better overall fitness.</P>
<P ALIGN="JUSTIFY">This method is very useful in the study of the transition zone between a phoneme a the next one. We can follow the changes of the formant parameters as a function of time and reconstruct what happens during the coarticulation process. With this method we was able to follow different transitions for example involving plosives. In order to evaluate the results obtained from the optimization we have used a perception test. Using the parameters found in the GA optimization a number of complete isolated word was generated with the synthesizer. Each word was presented 3 times (with a pause of 10 seconds)  to each subject which has to write what he/she has understood. The results in audio file format are available at: </P>
<FONT SIZE=4><P ALIGN="CENTER"></FONT><A HREF="http://www.fis.unipr.it/baricchi/tesi/tesi_progress.html"><U><FONT SIZE=4 COLOR="#0000ff">http://www.fis.unipr.it/baricchi/tesi/tesi_progress.html</U></FONT></A><I>.</P>
<P ALIGN="CENTER"></P>
<P ALIGN="CENTER">&nbsp;</P>
</I><B><FONT SIZE=5><P ALIGN="CENTER">Il MUSEIKA in giapponese: desonorizzazione, devocalizzazione o elisione vocalica?</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Antonella Bristot &amp; Rodolfo Delmonte</P>
</I></FONT><P ALIGN="CENTER">Sezione di Linguistica</P>
<P ALIGN="CENTER">Dipartimento Studi Asia Orientale</P>
<P ALIGN="CENTER">Universit&agrave; Ca&#146; Foscari &#151; Ca&#146; Garzoni-Moro</P>
<P ALIGN="CENTER">San Marco 3417 &#151; 30124 VENEZIA</P>
<P ALIGN="CENTER">Tel.:0412578464/52/19 &#151; Fax:0415287683</P>
<P ALIGN="CENTER">www: <A HREF="http://byron.cgm.unive.it/"><U><FONT SIZE=4 COLOR="#0000ff">http://byron.cgm.unive.it</U></FONT></A></P>
<P ALIGN="CENTER"></P>
<P ALIGN="JUSTIFY">Il<I> museika</I>, &egrave; un fenomeno che interessa principalmente le vocali alte giapponesi [<FONT FACE="ApiaaApiaa,Times">i</FONT>] e [<FONT FACE="PalPhon">}</FONT>], ed &egrave; riscontrato essenzialmente nel linguaggio informale della parlata di Tokyo. Dal punto di vista fonologico, quando queste vocali si trovano tra due consonanti ostruenti [-sonoro], o a fine morfema precedute da consonante [-sonoro], esse sono sottoposte a &quot;devoicing&quot;, rappresentate foneticamente come [<FONT FACE="PalPhon">i¾</FONT>] e [<FONT FACE="PalPhon">}¾</FONT>]. In questo lavoro proporremo una diversificazione graduata in tre livelli del &quot;devoicing&quot; a seconda che vi siano oppure no tracce formantiche nello spettro, che definiremo &quot;desonorizzazione&quot; e &quot;devocalizzazione&quot;, oltre ovviamente ad individuare i casi di  vera elisione vocalica.</P>
<P ALIGN="JUSTIFY">L&#146;esperimento che abbiamo compiuto prevede uno studio comparativo che mette a confronto termini che costituiscono prestiti lessicali provenienti dalla lingua inglese, denominati &quot;gairaigo&quot; in giapponese e termini preesistenti nel giapponese standard, allo scopo di verificare se l&#146;applicazione della regola fonologica di museika venga estesa automaticamente a questi nuovi elementi lessicali. Vale la pena notare che l&#146;applicazione della regola modifica comunque la pronuncia originale delle parole gairaigo che per poter essere introdotte nel giapponese devono rispettare in tutto e per tutto  la fonologia del giapponese. Le parole sono state pronunciate da parlanti di sesso maschile e femminile all&#146;interno di una frase quadro. L&#146;analisi spettrografica delle parole interessate dal <I>museika</I> ci ha permesso di distinguere chiaramente tra diversi tipi o gradi di &quot;devoicing&quot; dei vocoidi giapponesi. Dalle analisi compiute, la natura acustica e articolatoria della consonante che precede le vocali alte &egrave; fondamentale per la realizzazione del <I>museika</I>, ma vi sono altri fattori importanti che interagiscono con questo fenomeno.</P>
<P ALIGN="JUSTIFY">Vari studi compiuti sull&#146;argomento hanno rivelato che &egrave; possibile distinguere tra due tipi di <I>museika</I>. Quando la vocale alta &egrave; preceduta da una consonante occlusiva, sullo spettrogramma si riscontra la presenza sia di una barra vocale indicante la lieve vibrazione della glottide sia la presenza delle formanti. &Egrave; opinione generale che, in questo contesto, il <I>museika</I> pu&ograve; essere definito un caso di &quot;devoicing&quot;. Al contrario, se la vocale &egrave; preceduta da una fricativa, di norma, sullo spettrogramma si visualizza un rumore di tipo fricativo che non &egrave; caratterizzato n&eacute; dalla presenza della barra vocale n&eacute; delle formanti. In questo secondo caso, molti parlano di elisione vocalica.</P>
<P ALIGN="JUSTIFY">Tuttavia l&#146;elisione vocalica implica non solo la sparizione del segmento, ma anche la creazione, a conseguenza di ci&ograve;, di nessi consonantici non permessi dalla fonotattica giapponese. Poich&eacute; la lingua giapponese ha una struttura sillabica semplice in cui la sillaba meno marcata &egrave; del tipo (C)V(C), gli unici nessi permessi sono quelli creati da una sequenza di geminate, mentre sequenze di consonanti diverse sono evitate. Ne &egrave; una riprova il largo ricorso all&#146;epentesi vocalica nei <I>gairaigo</I>, dove i nessi consonantici del termine d&#146;origine vengono separati tramite l&#146;inserimento di una vocale, inserimento finalizzato all&#146;adattamento della struttura del termine straniero al sistema sillabico giapponese.</P>
<P ALIGN="JUSTIFY">Inoltre, chi definisce il &quot;devoicing&quot; nel contesto di una fricativa sorda un caso di elisione, non sembra prendere in considerazione lo sforzo compiuto dal parlante giapponese nel rilasciare lentamente la consonante che precede la vocale. L&#146;estensione articolatoria della consonante nella zona occupata dalla vocale non solo indica che del vocoide rimane una traccia, ma permette anche di preservare la struttura sillabica del termine. </P>
<P ALIGN="JUSTIFY">Partendo dalla considerazione che il &quot;devoicing&quot; dovrebbe implicare non solo l&#146;assenza di vibrazione delle corde vocali, ma anche l&#146;assenza delle formanti che caratterizzano questi suoni, proporremo un&#146;analisi diversificata delle vocali sottoposte a <I>museika</I> basata sul riscontro della presenza &#151; desonorizzazione - o assenza &#151; devocalizzazione - di tracce formantiche nello spettro. Sosterremo, inoltre, che anche in assenza delle formanti il <I>museika</I> pu&ograve; e deve venire trattato come un caso di &quot;devoicing&quot; e non di elisione vocalica.</P>
<P ALIGN="JUSTIFY">Analisi spettrografiche dei termini che presentano al loro interno vocali [-sonoro] hanno dimostrato che la presenza nello spettro di tracce formantiche non &egrave; condizione unica e obbligatoria per la realizzazione del <I>museika</I>. Si cercher&agrave; quindi di determinare quali altri fattori possono essere presi in considerazione e in base a quali argomentazioni si possa parlare di diversi tipi o gradi di &quot;devoicing&quot;</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=5><P ALIGN="CENTER">Problematiche e Risultati delle Ricerche Acustiche sull'Espressione</P>
<P ALIGN="CENTER">Vocale delle Emozioni</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Emanuela Magno Caldognetto</P>
</I></FONT><P ALIGN="CENTER">Istituto di Fonetica e Dialettologia &#151; C.N.R.</P>
<P ALIGN="CENTER">Via G. Anghinoni, 10 - 35121 Padova (ITALY)</P>
<P ALIGN="CENTER">e-mail: Emanuela <A HREF="mailto:Magno@csrf.pd.cnr.it"><U><FONT SIZE=3 COLOR="#0000ff">Magno@csrf.pd.cnr.it</U></FONT></A></P>
<P ALIGN="CENTER">www: <A HREF="http://www.csrf.pd.cnr.it/"><U><FONT SIZE=3 COLOR="#0000ff">http://www.csrf.pd.cnr.it</U></FONT></A></P>
<P>&nbsp;</P>
<P ALIGN="JUSTIFY">L'individuazione  degli indici acustici che veicolano la trasmissione delle  informazioni sullo stato affettivo del parlante e' diventata una tematica  rilevante anche nel campo della fonetica  perche' emozioni e attitudini  sono  riconosciute ormai  come  una delle componenti  del contesto dell'  interazione comunicativa faccia -a-faccia e come tali inserite nei piu'  attuali modelli pragmatici della conversazione elaborati , nelle  elaborazioni computazionali di dialogo proposti dall' Intelligenza  Artificiale e nelle diverse applicazioni  delle Tecnologie del parlato (sintesi e riconoscimento del parlato).</P>
<P ALIGN="JUSTIFY"> Tale individuazione risulta complessa a causa della cooccorrenza e  interazione degli indici acustici specifici delle informazioni paralinguistiche  con quelli che trasmettono le informazioni extralinguistiche  e linguistiche  che determinano una serie di problemi </P>
<P ALIGN="JUSTIFY">metodologici e teorici.</P>
<P ALIGN="JUSTIFY">Tra i primi rientrano ,per esempio:</P>
<P ALIGN="JUSTIFY">1) La tipologia del materiale da analizzare, che prevede la scelta tra emozioni reali e simulate, cioe' tra  enunciati spontanei e testi predeterminati o strutture fonologiche senza significato lessicale prodotti, con l'aiuto di scenari, da  attori o da parlanti non addestrati.</P>
<P ALIGN="JUSTIFY">2) La scelta dei parametri acustici presi in considerazione per definire le variazioni imposte dalla produzione delle emozioni rispetto alle produzioni non emotive, cioe' tanto caratteristiche spettrali (formanti, concentrazioni di rumore) delle unita'  segmentali, quanto  parametri cosiddetti soprasegmentali: F0, durata, intensita' . Questi ultimi possono essere  valutati sia globalmente, cioe'  relativamente a tutto un enunciato (il cosiddetto  livello macroprosodico), sia  localmente (livello microprosodico), cioe' con analisi rivolte ad individuare le specifiche variazioni dei singoli parametri in relazione  o alle vocali toniche o alle sillabe iniziali o finali di sintagmi o dell'enunciato.</P>
<P ALIGN="JUSTIFY"> Tra questi parametri F0 e' il piu' dettagliatamente studiato tanto quantitativamente, in termini di valori sia assoluti (massimi, minimi, medi, rang, span) che relativi (per i quali si richiedono </P>
<P ALIGN="JUSTIFY">operazioni di normalizzazione e il ricorso ad unita' di misura diverse dagli Hertz, p.es. le ottave) e di qualita'  non modali della voce (presenza di laringalizzazioni, voce rauca, voce sussurrata, atti fonatori speciali quali  risate, singhiozzi, inspirazioni), quanto qualitativamente, in termini di andamenti intonativi globali e locali.</P>
<P ALIGN="JUSTIFY">In relazione a tali andamenti fonetisti e fonologi si devono porre una serie di interessanti  problemi teorici:  se gli andamenti intonativi determinati dalle emozioni siano discreti o scalari, se si sovrappongano addizionalmente all'intonazione definita dalla struttura sintattica degli enunciati non emotivi o se invece si debbano  ipotizzare delle intonazioni pianificate globalmente  per enunciati  con nuove caratteristiche pragmatiche, per le quali quindi  si dovrebbe poter definire un inventario di unita'  con specifiche forme e funzioni.</P>
<P ALIGN="JUSTIFY">Nel corso dell'intervento saranno presentati esempi sperimentali atti ad illustrare le problematiche esposte e i risultati ottenuti dalle ricerche in corso presso l'IFeD che riguardano prevalentemente la caratterizzazione macroprosodica multidimensionale delle emozioni.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=5><P ALIGN="CENTER">Implicazioni Linguistiche e Psicolinguistiche delle Ricerche Fonetiche sulle &quot;FACCE PARLANTI&quot;</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Emanuela Magno Caldognetto, Claudio Zmarich</P>
</I></FONT><P ALIGN="CENTER">Istituto di Fonetica e Dialettologia &#151; C.N.R.</P>
<P ALIGN="CENTER">Via G. Anghinoni, 10 - 35121 Padova (ITALY)</P>
<P ALIGN="CENTER">e-mail: Emanuela <A HREF="mailto:Magno@csrf.pd.cnr.it"><U><FONT SIZE=3 COLOR="#0000ff">Magno@csrf.pd.cnr.it</U></FONT></A></P>
<P ALIGN="CENTER">www: <A HREF="http://www.csrf.pd.cnr.it/"><U><FONT SIZE=3 COLOR="#0000ff">http://www.csrf.pd.cnr.it</U></FONT></A></P>
<P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="JUSTIFY">La prima parte delle comunicazione sar&agrave; dedicata all&#146;esposizione riassuntiva delle ricerche condotte presso l&#146;IFD sui movimenti labiali e mandibolari in strutture VCV (C=21 consonanti italiane; V= i, a, u). Queste ricerche hanno lo scopo di quantificare le caratteristiche del segnale ottico che trasmette l&#146;informazione linguistica. In questa relazione non si illustreranno le possibili utilizzazioni di tali dati nelle tecnologie multimodali del parlato, ma la loro rilevanza linguistica e psicolinguistica.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">La seconda parte della comunicazione discuter&agrave; alcune problematiche linguistiche:</P>

<UL>
<P ALIGN="JUSTIFY"><LI>a livello di produzione, la maggior adeguatezza delle nuove fonologie articolatorie alla spiegazione dei rapporti tra fonetica e fonologia, cio&egrave; tra movimenti articolatori e rappresentazione linguistica [1];</LI></P>
<P ALIGN="JUSTIFY"><LI TYPE="1" VALUE=1>quantificazione dell&#146;informazione fonologica trasmessa dai movimenti articolatori visibili  (<B>visemi</B>);</LI></P>
<P ALIGN="JUSTIFY"><LI TYPE="1">necessit&agrave; degli studi contrastivi, perch&eacute; l&#146;italiano presenta caratteristiche peculiari sia per inventario fonetico che per diversa utilizzazione dello spazio articolatorio (cfr. per es. [2] per l&#146;inglese e [3] per il giapponese).</LI></P>
<P ALIGN="JUSTIFY"><LI TYPE="1">dati sperimentali alla base del fenomeno del sinergismo nell&#146;interazione tra le informazioni fonologiche trasmesse dalla modalit&agrave; uditiva e quella visiva.</LI></P></UL>

<P ALIGN="JUSTIFY">La terza parte della comunicazione illustrer&agrave; alcuni problemi psicolinguistici e cognitivi:</P>
<OL>

<P ALIGN="JUSTIFY"><LI>rappresentazione plurisensoriale delle unit&agrave; fonologiche; </LI></P>
<P ALIGN="JUSTIFY"><LI VALUE=1>la quantificazione dell&#146;effetto<B> sinergico</B>, cioe&#146; dell&#146;aumento dell&#146;intelligibilita&#146; nella percezione contemporanea dei due segnali visivo e uditivo, che ha luogo normalmente nell&#146;interazione comunicativa faccia a faccia [4, 5].</LI></P>
<P ALIGN="JUSTIFY"><LI>la riflessione sui <B>modelli di integrazione</B> dei due tipi di informazione, uditiva e visiva, che prevedono differenti possibilit&agrave;:</LI></P></OL>


<UL>
<P ALIGN="JUSTIFY"><LI>identificazione separata delle due fonti di informazione;</LI></P>
<P ALIGN="JUSTIFY"><LI>identificazione basata su ricodificazione a modalit&agrave; dominante (o uditiva, o articolatoria);</LI></P>
<P ALIGN="JUSTIFY"><LI>identificazione basata su ricodificazione amodale fondata sulla dinamica articolatoria. </LI></P></UL>

<OL>

<P ALIGN="JUSTIFY"><LI>la formulazione di teorie quali la <B>teoria motoria di percezione della parola</B> [6] e la <B>teoria diretta di percezione dell&#146;evento </B>[7], che sono alternative rispetto alle tradizionali teorie acustico-uditive.</LI></P></OL>

<P ALIGN="JUSTIFY">Per concludere, la quarta parte discuter&agrave; le implicazioni del concetto di visema nelle problematiche dell&#146;accesso al lessico. Infatti, se la conversazione faccia a faccia avviene in presenza di condizioni ambientali avverse o le capacit&agrave; uditive dell&#146;ascoltatore sono ridotte, la confluenza dei 21 fonemi consonantici dell&#146;italiano in un numero ridotto di visemi determina una riduzione della trasmissione dell&#146;informazione fonologica, con la creazione di parole <B>omofene</B>, cio&egrave; quelle parole che sono diverse uditivamente, ma che invece sono simili in termini di lettura labiale. L&#146;omofenia ha effetti negativi sull&#146;accesso al lessico perch&eacute; molte parole omofene e non omofone corrispondono ad una stessa stringa di visemi. </P>
<P ALIGN="JUSTIFY"> </P>
<B><P ALIGN="JUSTIFY">BIBLIOGRAFIA</P>
<OL>

</B><P ALIGN="JUSTIFY"><LI>Browman C.P. &amp; Goldstein L., Dynamics and Articulatory Phonology, in R.F. Port &amp; T. van Gelder (Eds.), <I>Mind as Motion</I>, MIT Press, Cambridge (Mass), 1995, 175-193.</LI></P>
<P ALIGN="JUSTIFY"><LI VALUE=1>Walden B.E., Prosek R.A., Montgomery A.A., Scherr C.K. &amp;  Jones C.J., Effects of Training on the Visual Recognition of Consonants, <I>Journal of Speech and Hearing Research</I> 20, 1977,130-145.</LI></P>
<P ALIGN="JUSTIFY"><LI>Hiki S. &amp; Fukuda Y., Negative effect of omophones on speechreading in japanese&quot;, in C. Benoit &amp; R. Campbell (Eds.), Proceedings of AVSP&#146;97, Rhodes, 26-27 Sept. 1997, 9-12.</LI></P>
<P ALIGN="JUSTIFY"><LI>Erber N.P., Auditory-Visual Perception of Speech, <I>Journal of Speech and Hearing  Disorders</I>, 40, 1975, 481-492.</LI></P>
<P ALIGN="JUSTIFY"><LI>Mohamadi T. &amp; Benoit C., Apport de la vision du locuteur &agrave; l&#146;intelligibilite&#146; de la parole bruit&eacute;e en fran&ccedil;ais,<I> Bulletin de la Communication Parl&eacute;e</I> 2, 1992, 31-41. </LI></P>
<P ALIGN="JUSTIFY"><LI>Liberman A.M. &amp; Mattingly I.G., The Motor Theory of Speech Perception Revised, <I>Cognition</I>, 21, 1985, 1-36.</LI></P>
<P ALIGN="JUSTIFY"><LI>Fowler C. A., An Event Approach to the Study of Speech Perception from a  Direct-Realist Perspective, <I>Journal of Phonetics</I>, 14, 1986.</LI></P></OL>

<FONT FACE="Helvetica" SIZE=1><P ALIGN="JUSTIFY"> </P>
</FONT><B><FONT SIZE=5><P ALIGN="CENTER">Il modello di resa delle intenzioni espressive nell'esecuzione musicale/vocale mediante analisi-sintesi del Centro di Sonologia Computazionale di Padova</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Sergio Canazza</P>
</I></FONT><P ALIGN="CENTER">Centro di Sonologia Computazionale</P>
<P ALIGN="CENTER">Dip. di Elettronica e Informatica</P>
<P ALIGN="CENTER">Universita' di Padova</P>
<FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><P ALIGN="JUSTIFY">Si presentera' una classe di tecniche di analisi in grado di dare una descrizione su piu' livelli della performance,  sia sul piano simbolico che su quello acustico. Al fine di produrre una completa descrizione della voce cantante, differenti livelli di analisi del segnale e della performance sono stati integrati in una stessa metodologia. Queste analisi sono utilizzate al fine di giungere alla costruzione di un modello in grado di sintetizzare (mediante MIDI o tecniche di post processing) performance musicali o vocali con diverse intenzioni espressive. Saranno presentate diversi esempi di analisi e risintesi della performance musicale/vocale.</P>
<FONT SIZE=4><P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
</FONT><B><FONT SIZE=5><P ALIGN="CENTER">Valutazione delle prestazioni di un segmentatore per l&#146;italiano.</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Fabrizio Balducci, Loredana Cerrato, Domenico D&#146;Alterio</P>
</I></FONT><P ALIGN="CENTER">Contact author:Dott.Loredana Cerrato</P>
<P ALIGN="CENTER">Speech Communication Group</P>
<P ALIGN="CENTER">Fondazione Ugo Bordoni</P>
<P ALIGN="CENTER">via B. Castiglione, 59</P>
<P ALIGN="CENTER">00142 Roma</P>
<P ALIGN="CENTER">tel. 06 54803355</P>
<P ALIGN="CENTER">fax 06 54804405</P>
<P ALIGN="CENTER">e-mail: <A HREF="mailto:loredana@fub.it"><U><FONT SIZE=4 COLOR="#0000ff">loredana@fub.it</U></FONT></A></P>
<FONT SIZE=4><P ALIGN="CENTER"></FONT><A HREF="http://www.fub.it/"><U><FONT SIZE=4 COLOR="#0000ff">www.fub.it</U></FONT></A></P>
<P ALIGN="CENTER"></P>
<B><P ALIGN="JUSTIFY">Abstract</P>
</B><P ALIGN="JUSTIFY">La segmentazione e l&#146;etichettamento del parlato forniscono un&#146;interfaccia tra parametri acustici fisicamente misurabili e categorie fonologiche astratte. Tra le applicazioni di un segmentatore vi &egrave; quella di etichettare segnali, anche di cattiva qualit&agrave;, al fine di studiare particolari fonemi ad esempio nell&#146;ambito applicativo del riconoscimento del parlatore.</P>
<P ALIGN="JUSTIFY">Per valutare le prestazioni del sistema di riconoscimento RES, realizzato dal gruppo di comunicazioni vocali della Fondazione Bordoni, si presentano i risultati di un test di valutazione eseguito sul database APASCI opportunamente modificato per applicazioni telefoniche.</P>
<P ALIGN="JUSTIFY">Il sistema RES (Recognition Experimental System), con il quale sono stati condotti gli esperimenti, &egrave; un sistema per il riconoscimento statistico del parlato continuo, che &egrave; stato opportunamente modificato per la realizzazione di un algoritmo di segmentazione.</P>
<P ALIGN="JUSTIFY">I risultati ottenuti sono stati valutati confrontando i limiti individuati automaticamente con quelli della segmentazione manuale di riferimento fornita con il database. Il 41.5% dei limiti di fonema individuati presentano uno scostamento inferiore ai 5ms rispetto alla segmentazione di riferimento, mentre l&#146;88% &egrave; al di sotto dei 20ms.</P>
<FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=5><P ALIGN="CENTER">OGI Toolkit.</P>
</B><P ALIGN="CENTER">Il riconoscimento automatico del linguaggio</P>
<P ALIGN="CENTER">naturale alla portata di tutti.</P>
</FONT><I><FONT SIZE=4><P ALIGN="CENTER">Piero Cosi</P>
</I></FONT><FONT SIZE=3><P ALIGN="CENTER">Istituto di Fonetica e Dialettologia &#151; C.N.R.</P>
<P ALIGN="CENTER">Via G. Anghinoni, 10 - 35121 Padova (ITALY)</P>
<P ALIGN="CENTER">e-mail: </FONT><A HREF="mailto:cosi@csrf.pd.cnr.it"><U><FONT SIZE=3 COLOR="#0000ff">cosi@csrf.pd.cnr.it</U></FONT></A></P>
<FONT SIZE=3><P ALIGN="CENTER">www: </FONT><A HREF="http://www.csrf.pd.cnr.it/"><U><FONT SIZE=3 COLOR="#0000ff">http://www.csrf.pd.cnr.it</U></FONT></A></P>
<B><P ALIGN="CENTER">SOMMARIO</P>
</B><FONT FACE="Times New Roman,Times New Roman"><P ALIGN="JUSTIFY">I sistemi di riconoscimento automatico del linguaggio naturale rendono possibile all&#146;uomo di interagire con il computer mediante la voce, il metodo di comunicazione umana pi&ugrave; naturale e comune. Questi sistemi sono studiati e realizzati mediante le conoscenze acquisite nel corso degli ultimi anni nel campo del riconoscimento automatico, dell&#146;elaborazione del linguaggio naturale e delle tecnologie per l&#146;interfaccia uomo-macchina. Essenzialmente si basano sul riconoscimento delle parole pronunciate, sull&#146;interpretazione della loro sequenza al fine di ottenerne un opportuno significato e sull&#146;attuazione di un&#146;adeguata risposta. Le potenziali applicazioni sono numerosissime e, sebbene questi sistemi siano sostanzialmente agli albori, &egrave; oltremodo facile intuire la loro enorme potenzialit&agrave; nel poter rivoluzionare il modo in cui le persone nel futuro si rapporteranno con le macchine. Interagendo in modo naturale, senza cio&egrave; dover sottostare ad una specifica fase di addestramento, un sempre gran numero di persone, non necessariamente specializzate, sar&agrave; introdotto all&#146;uso di queste tecnologie. Negli ultimi anni le tecnologie relative alla realizzazione di questi sistemi di riconoscimento automatico del linguaggio naturale hanno subito una fortissima accelerazione e numerosi e notevoli sono stati i passi avanti compiuti nel campo della ricerca. Come risultato, si possono a tutt&#146;oggi osservare un gran numero di sistemi funzionanti in compiti specifici quali la pianificazione di viaggi, l&#146;esplorazione urbana etc.. Ormai, non si pu&ograve; pi&ugrave; parlare di esclusivi prototipi di ricerca appannaggio di elitari laboratori scientifici, ma di vere e proprie applicazioni operanti in tempo-reale, su parlato continuo, indipendentemente dal parlante che non deve pi&ugrave; sottostare a lunghe sedute di addestramento, e supportati da vocabolari di 1000 e pi&ugrave; parole. Questi sistemi devono essere assai pi&ugrave; robusti degli iniziali prototipi di ricerca in quanto devono essere utilizzati in condizioni naturali quindi in presenza di rumore, sia di canale sia di ambiente, in condizioni di utilizzo che devono essere ugualmente soddisfacenti indipendentemente dal variare della velocit&agrave; di eloquio, dell&#146;accento o del sesso dell&#146;utilizzatore. Devono esibire inoltre un comportamento &#145;intelligente&#146;, devono cio&egrave; essere in grado di saper reagire anche in condizioni di parziale riconoscimento, che pu&ograve; avvenire in seguito all&#146;occorrenza di pronunce scorrette da parte dell&#146;utente o a causa di altri fenomeni indesiderati. Dovranno esibire inoltre la capacit&agrave; di integrarsi efficacemente con altre modalit&agrave; di comunicazione, cercando di &#145;capire&#146; in anticipo le intenzioni dell&#146;utente attraverso le sue espressioni facciali, il movimento delle labbra, degli occhi etc. e sfruttando tutte le molteplici potenzialit&agrave; multimediali offerte dalla tecnologia per elaborare le proprie azioni in risposta ai quesiti dell&#146;utente rendendo l&#146;interazione oltremodo naturale ed immediata.</P>
<P ALIGN="JUSTIFY">Per poter sfruttare al massimo questa nuova tecnologia un sempre maggior numero di laboratori deve poter disporre di strutture informative adeguate ed &egrave; impensabile che le conoscenze necessarie allo sviluppo di una tale tecnologia siano parcellizzate e non comunemente utilizzabili. E&#146; con questo obiettivo che all&#146; &#145;<I>Oregon Graduate Institute&#146;</I> (<I>OGI</I>) di Portland ed in particolare presso il &#145;<I>Center for Spoken Language Understanding</I>&#146; (<I>CLSU</I>) sono stati sviluppati dei &#145;tools&#146; denominati <I>OGI-Toolkit</I> [1] che hanno proprio lo scopo di fornire ad un sempre pi&ugrave; elevato numero di ricercatori, come anche di non addetti ai lavori, degli strumenti necessari per creare e sviluppare personalmente in modo semplice ed interattivo nuovi sistemi di riconoscimento del linguaggio naturale sempre pi&ugrave; orientati alle applicazioni. In questo lavoro vengono descritte le principali funzionalit&agrave; degli OGI-Toolkit che costituiscono un insieme integrato di tecnologie software specializzate rappresentanti lo &#145;stato dell&#146;arte&#146; negli strumenti per la ricerca, lo sviluppo e l&#146;apprendimento dei sistemi di riconoscimento del linguaggio naturale. Sono presentati inoltre i risultati ottenuti nel riconoscimento automatico di stringhe di numeri pronunciati in modo connesso in modalit&agrave; indipendente dal parlante, su canale telefonico, mediante la realizzazione di tre differenti architetture completamente realizzate mediante l&#146;applicazione degli OGI-Toolkit. In particolare, saranno descritti in dettaglio, rispettivamente, un sistema basato sulle Reti Neurali Artificiali, un sistema basato sulle Catene di Markov Nascoste ed uno su una struttura ibrida comprendente entrambe le due strutture precedentemente citate. I risultati ottenuti sono fra i migliori apparsi in letteratura su un corpus analogo.</P>
</FONT><B><P ALIGN="CENTER">BIBLIOGRAFIA</P>
</B><P ALIGN="JUSTIFY">[1] P.Cosi, J.P. Hosom, J. Shalkwyk, S. Sutton, and R. A. Cole, &#145;Connected Digit Recognition Experiments with the OGI Toolkit's Neural Network and HMM-Based Recognizers&#146;, to be published in Proceedings of The 4th IEEE workshop on Interactive Voice Technology for Telecommunications Applications and ESCA Tutorial and Research Workshop on Applications of Speech Technology in Telecommunications, Torino (Italy), 29 - 30 September 1998.</P>
<I><P ALIGN="JUSTIFY"></P>
</I><P ALIGN="CENTER">&nbsp;</P>
<B><FONT FACE="Times New Roman,Times New Roman" SIZE=5><P ALIGN="CENTER">Intonazione delle modalit&agrave; naturali rappresentative: analisi e sintesi</P>
</B></FONT><FONT FACE="Times New Roman,Times New Roman"><P ALIGN="JUSTIFY"></P>
<I><P ALIGN="CENTER">Emanuela Cresti, Philippe Martin, Massimo Moneglia</P>
<P ALIGN="CENTER">(Universit&agrave; di Firenze e Universit&agrave; di Toronto)</P>
</I><P ALIGN="CENTER">Comunicazioni a Massimo Moneglia  </P>
<P ALIGN="CENTER">e-mail  </FONT><A HREF="mailto:moneglia@cesit1.unifi.it"><U><FONT SIZE=4 COLOR="#0000ff">moneglia@cesit1.unifi.it</U></FONT></A></P>
<FONT FACE="Times New Roman,Times New Roman"><P ALIGN="CENTER"></P>
<P ALIGN="JUSTIFY">E' noto che esiste un rapporto molto stretto tra l'intonazione di frase e l'espressione della modalit&agrave;: dichiarativa, interrogativa, iussiva (Denes, 1960; Fonagy, 1987; Fava, 1995;  Bertinetto-Magno Caldognetto, 1993).</P>
<P ALIGN="JUSTIFY">  Nonostante vari lavori (Magno-Caldognetto et alii, 1978 Sorianello, 1995; Caputo, 1996; Maturi, 1998; Schirru, 1981; Canepari, 1985; Cresti, 1994) non esiste ancora per l'italiano una descrizione complessiva delle tipologie intonative corrispondenti all'espressione della modalit&agrave; di frase, ma soprattutto risulta difficile a livello teorico, isolare i caratteri pertinenti di tale indagine.</P>
<P ALIGN="JUSTIFY">  Un'importante linea di ricerca segue dall'idea che nel parlato spontaneo le entit&agrave; linguistiche da considerare non siano tanto frasi caratterizzate da una diversa modalit&agrave; ma enunciati che realizzano atti linguistici (Austin 1962) con diversa forza illocutoria. Essi sono sistematicamente letti da gruppi di unit&agrave; tonali (pattern intonativo 't Hart et alii 1990), e si strutturano a partire dall'unit&agrave; tonale di comment, che &egrave; caratterizzata dall'espressione dell'illocuzione e che &egrave; necessaria e pu&ograve; essere sufficiente a costituire il pattern (Cresti 1987 e seguenti). </P>
<P ALIGN="JUSTIFY">  Le variazioni di F0 che permettono il riconoscimento percettivo dell'unit&agrave; di comment sono oggetto di indagine. All'interno di tale indagine assume un'importanza particolare lo studio dell'intonazione di enunciati semplici, composti da una sola unit&agrave; di comment, e l'attribuzione di valore alle loro variazioni prosodiche su base percettiva.</P>
<P ALIGN="JUSTIFY">  La comunicazione presenta i risultati di una ricerca</P>
<P ALIGN="JUSTIFY">che considera: a) un comment semplice, come un predicato nominale  "&egrave; Filippo", che dovrebbero essere valutata come frase di tipo dichiarativo; b) la sua realizzazione in diversi contesti "elicitanti" di risposta, deissi, identificazione, conclusione, azioni che sono tradizionalmente tutte considerate all'interno della illocuzione rappresentativa (Searle 1978); c) le sistematiche variazioni d'intonazione dell'espressioni realizzate nei diversi contesti.</P>
<P ALIGN="JUSTIFY">Le produzioni, realizzate in laboratorio da locutori maschili e femminili, in contesti elicitanti controllati sulla base di una definizione esplicita delle caratteristiche informative di ciascun contesto, mostrano una notevole costanza formale dei profili tonali sia al variare della struttura accentuale del predicato nominale in questione (ossitona, parossitona, proparossitona) e della micromelodia di parola ("&egrave; Massimo"; "&egrave; Maril&ugrave;), che al variare dei locutori.</P>
<P ALIGN="JUSTIFY">  I profili tonali dei comment prodotti in ciascun contesto elicitante saranno descritti in dettaglio secondo la teoria di Ph. Martin (1979, 1987). </P>
<P ALIGN="JUSTIFY">  L'esistenza di profili tonali con valore differenziale all'interno di una pi&ugrave; generale tipologia rappresentativa, non &egrave; immediatamente inferibile sulla base dell'analisi dei profili, ma pu&ograve; essere sostenuta a livello sperimentale a seguito di una validazione percettiva condotta su due gruppi distinti di dieci parlanti competenti confrontati con enunciati naturali e di sintesi. La validazione ha mostrato che: </P>
<P ALIGN="JUSTIFY">1) date le restrizioni informative che definiscono i contesti, i soggetti mostrano una chiara preferenza e giudicano naturali i profili elicitati in ciascun contesto, mentre sono rifiutate massicciamente, al di l&agrave; di ogni attesa, le varianti proprie degli altri contesti;</P>
<P ALIGN="JUSTIFY">2) la sintesi dei profili tonali sottoposta agli stessi soggetti ottiene risultati paragonabili, mostrando la pertinenza melodica delle variazioni.</P>
<P ALIGN="JUSTIFY">Ne deriva l'evidenziazione di profili tonali di valore differenziale, connessi all'espressione di modalit&agrave; rappresentative diverse, e il valore naturale delle restrizioni informative che le definiscono (Moneglia-Cresti, 1997).</P>
<P ALIGN="JUSTIFY">L'analisi e la sintesi dei diversi enunciati &egrave; stata eseguita con il sistema Win Pitch di Ph. Martin.</P>
<P ALIGN="JUSTIFY"> </P>
</FONT><P ALIGN="JUSTIFY"></P>
<B><FONT SIZE=5><P ALIGN="CENTER">Il tempo della voce</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Francesco Cutugno</P>
</I></FONT><P ALIGN="CENTER">CIRASS - Centro Interdipartimentale di Ricerca per l'Analisi e la Sintesi</P>
<P ALIGN="CENTER">dei Segnali.</P>
<P ALIGN="CENTER">tel  +39 81 5420281  fax +39 81 5420370</P>
<P ALIGN="CENTER">Universit&agrave; degli Studi di Napoli Federico II</P>
<FONT SIZE=4><P ALIGN="CENTER"></FONT><A HREF="http://www.unina.it/cirass"><U><FONT SIZE=4 COLOR="#0000ff">http://www.unina.it/cirass</U></FONT></A></P>
<P ALIGN="CENTER">e-mail <A HREF="mailto:cutugno@unina.it"><U><FONT SIZE=4 COLOR="#0000ff">cutugno@unina.it</U></FONT></A></P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">Il ritmo delle lingue, inteso come l'insieme delle regolarit&agrave; temporali presenti all'interno del codice fonetico, &egrave; oggetto di studio di fonologi, fonetisti e psicolinguisti. Le teorie di fonologia prosodica, danno una descrizione delle caratteristiche ritmiche della lingua basata sulla definizione di strutture gerarchiche ad albero binario. Le unit&agrave; minime di analisi sono il piede e/o la sillaba, e l'alternanza regolare fra posizioni forti e deboli viene considerata come caratteristica universale (Principio dell'Alternanza Ritmica - PRA). </P>
<P ALIGN="JUSTIFY">Sul versante fonetico, coerentemente con le descrizioni fonologiche, tali regolarit&agrave; si realizzano nelle caratteristiche di sviluppo temporale del codice acustico. Ne conseguono disegni sperimentali che cercano di inquadrare foneticamente le lingue in tipologie metriche rigide (cfr. la distinzione fra isocronismo sillabico e isocronismo accentuale) che difficilmente giungono a conclusioni scevre da incertezza. </P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">Il punto di vista del ricevente &egrave; quello pi&ugrave; trascurato dalla ricerca linguistica, ma &egrave; caro a quella psicolinguistica. Ad ogni modo l'influenza delle teorie fonologiche e fonetiche &egrave; forte anche fra gli specialisti di questo ambito: buona parte della ricerca sul <I>processing</I> del segnale acustico indaga sulla forma dei presunti meccanismi che consentono al ricevente di "allinearsi" temporalmente al flusso <I>regolare</I> delle informazioni ricevute e su come il ritmo, pensato come fenomeno ciclico, possa essere impiegato per segmentare la catena fonica continua. </P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">In questo tipo di studi &egrave; celata una visione della comunicazione audioverbale come processo <I>sincrono</I>, cio&egrave; un processo di scambio di informazioni nel quale il codice &egrave; dotato di caratteristiche temporali regolari che consentono una contemporaneit&agrave; relativa fra il processo di produzione e quello di ricezione.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">Scopo della presente comunicazione &egrave; indagare su questa presunta sincronicit&agrave;. Ci&ograve; verr&agrave; fatto mediante un confronto delle problematiche di ambito fonetico e quelle di ambito percettivo-psicolinguistico articolato in due fasi:</P>
<P ALIGN="JUSTIFY"></P><DIR>
<DIR>
<DIR>

<P ALIGN="JUSTIFY">1) una rassegna di studi fonetici relativi alla misura delle durate di unit&agrave; segmentali e soprasegmentali in parlato letto, o comunque prodotto per scopi specifici di ricerca e in parlato connesso: mentre nel primo dei due stili possono (ma non sempre) riscontrarsi propriet&agrave; temporali regolari, nel secondo &egrave; praticamente impossibile individuare caratteristiche ritmico-temporali regolari;</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">2) una analisi dei principali modelli psicolinguistici sul <I>processing </I>del segnale incentrate sull'uso da parte dell'ascoltatore delle propriet&agrave; temporali del segnale vocale per la segmentazione della catena fonica continua, l'individuazione delle unit&agrave; minime di analisi, l'accesso al lessico e il riconoscimento delle parole. </P>
<P ALIGN="JUSTIFY"></P></DIR>
</DIR>
</DIR>

<P ALIGN="JUSTIFY">Seguir&agrave; una discussione sulla validit&agrave; dell'ipotesi di sincronia a cui si &egrave; fatto cenno in precedenza. Verr&agrave; anche formulata una proposta alternativa delle modalit&agrave; di comunicazione audio-verbale in termini di processo cognitivo di tipo <I>asincrono</I>. </P>
<P ALIGN="JUSTIFY">In questo tipo di processi il codice trasmesso non possiede necessariamente regolarit&agrave; temporali prevedibili, i partecipanti alla comunicazione eseguono i loro rispettivi compiti con modalit&agrave; e scansioni temporali indipendenti e la ricostruzione delle informazioni codificate da parte del ricevente, avviene grazie all'accumulo delle informazioni in un <I>buffer</I> di memoria a breve termine. Il <I>processing </I>deve in questo caso prevedere un meccanismo di analisi capace di muoversi retroattivamente nel buffer o di aspettare l'arrivo di ulteriori informazioni in tempi successivi non prevedibili. </P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<P ALIGN="JUSTIFY">&nbsp;</P><DIR>
<DIR>

<B><FONT SIZE=5><P ALIGN="CENTER">Prosodic Variability: from Syllables to Syntax through Phonology</P></DIR>
</DIR>

</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Rodolfo Delmonte</P>
</I></FONT><P ALIGN="CENTER">Sezione di Linguistica</P>
<P ALIGN="CENTER">Dipartimento Studi Asia Orientale</P>
<P ALIGN="CENTER">Universit&agrave; Ca&#146; Foscari &#151; Ca&#146; Garzoni-Moro</P>
<P ALIGN="CENTER">San Marco 3417 &#151; 30124 VENEZIA</P>
<P ALIGN="CENTER">Tel.:0412578464/52/19 &#151; Fax:0415287683</P>
<FONT SIZE=2><P ALIGN="CENTER">e-mail: </FONT><A HREF="mailto:cristina@fub.it"><U><FONT FACE="Courier New" SIZE=2 COLOR="#0000ff">delmont@unive.it</U></FONT></A></P>
<P ALIGN="CENTER">www: <A HREF="http://byron.cgm.unive.it/"><U><FONT SIZE=4 COLOR="#0000ff">http://byron.cgm.unive.it</U></FONT></A></P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<P ALIGN="JUSTIFY">Variability in timing and phrasing can be nicely accounted for in multilingual contexts by taking syllables as the phonological interface from higher linguistic levels - syntactic, lexical, semantic, to lower phonetic-acoustic levels. We shall comment on the hypothesis put forward by Campbell, Isard, Breen among others, that syllables be used as the most appropriate linguistic units both in timing models for text-to-speech synthesis systems and in recognition systems: in both cases HMMs or NNs would be trained on higher level linguistic factors affecting syllable timing rather than on phone-like segments, whose duration would be inferred/induced from the interplay of syllable type and its constraining factors, with intrinsic phone mean duration values. As to phrasing, we shall comment on the need to extend the number of Boundaries to better approximate spontaneous speech, by introducing a set of syntactic prosodic boundaries intended to cover an extended number of linguistic phenomena typical of dialogue from work being done in Verbmobil on the German language reported by Batliner et al. We shall also comment on factors related to syllable-based duration model in English by the above mentioned autors. Finally we shall use this kind of prosodic labelling to comment on our duration data for Italian.</P>
<P ALIGN="JUSTIFY"></P>
<B><P ALIGN="JUSTIFY">Bibliography</P>
<P ALIGN="JUSTIFY"></P><DIR>
<DIR>

</B><P ALIGN="JUSTIFY">Batliner A., R.Kompe, A.Kiessling, M.Mast, H.Niemann, E.Noeth (1998), <I>M - Syntax + Prosody: A syntactic-prosodic labelling scheme for large spontaneous speech databases</I>, in Speech Communication, 25, 4, 193-222.</P>
<P ALIGN="JUSTIFY">van Santen J., C.Shih, B.Moebius, E.Tzoukermann, M.Tanenblatt (1997), <I>Multi-Lingual Duration Modeling</I>, in Eurospeech&#146;97, Rhodos, Vol.3, 2651-2654.</P>
<P ALIGN="JUSTIFY">Breen A.P. (1995), <I>A Simple Method of Predicting the Duration of Syllables</I>, Eurospeech&#146;95, 595-598.</P>
<P ALIGN="JUSTIFY">van Son R.H., J. van Santen (1997), <I>Strong Interaction between Factors Influencing Consonant Duration,</I> in Eurospeech &#145;97, Rhodos, Vol.1, 319-322. </P>
<P ALIGN="JUSTIFY">Campbell W., S.Isard (1991), <I>Segment durations in a syllable frame</I>, in Journal of Phonetics 19, 37-47.</P></DIR>
</DIR>

<P ALIGN="JUSTIFY">Campbell W.  (1993), <I>Predicting Segmental Durations for Accomodation within a Syllable-Level Timing Framework</I>, Eurospeech &#145;93, 1081-1085.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=5><P ALIGN="CENTER">Valutazione di Corpora Generati a Partire da Scenari Testuali e Visivi</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">C. Delogu, D. Aiello, A. Di Carlo, M. Nisi, S. Tummeacciu</P>
</I></FONT><P ALIGN="CENTER">Cristina Delogu</P>
<P ALIGN="CENTER">Speech Communication Group</P>
<P ALIGN="CENTER">Multimedia Communication Department</P>
<P ALIGN="CENTER">Fondazione Ugo Bordoni</P>
<P ALIGN="CENTER">v. B. Castiglione 59 00142 Roma Italy</P>
<P ALIGN="CENTER">tel: + 39 06 54803354; fax: + 39 06 54804405</P>
<P ALIGN="CENTER">e-mail: <A HREF="mailto:cristina@fub.it"><U><FONT FACE="Courier New" SIZE=2 COLOR="#0000ff">cristina@fub.it</U></FONT></A></P>
<FONT FACE="Courier New" SIZE=2><P ALIGN="CENTER"></FONT><A HREF="http://www.fub.it/"><U><FONT FACE="Courier New" SIZE=2 COLOR="#0000ff">http://www.fub.it</U></FONT></A></P>
<P ALIGN="CENTER"></P>
<P>&nbsp;</P>
<P ALIGN="JUSTIFY">I corpora per applicazioni come l'interrogazione di banche dati via voce o la traduzione automatica voce-voce, devono contenere parlato spontaneo ottenuto in modo naturale da parlatori a cui vengono presentate delle descrizioni del dominio di applicazione, ovvero degli scenari. Gli scenari devono stimolare i parlatori nella generazione di frasi con un'ampia variet&agrave; di parole e frasi. Generalmente, nell'acquisizione di corpora vocali vengono usati scenari testuali (ST). In questo lavoro viene presentato un confronto tra ST e scenari visivi (SV), in cui la situazione viene visualizzata sotto forma di vignetta. Allo scopo di valutare possibili differenze tra scenari testuali e visivi, abbiamo condotto un esperimento con 100 soggetti suddivisi in due gruppi: Gruppo ST e Gruppo SV. In particolare, volevamo testare le seguenti ipotesi: (i) le frasi prodotte dal gruppo SV sono pi&ugrave; complesse di quelle prodotte dal gruppo ST; e (ii) le frasi prodotte dal gruppo SV sono pi&ugrave; difficili da modellare di quelle prodotte dal gruppo ST. La verifica delle ipotesi &egrave; stata fatta attraverso l'analisi della  "word intersection" e l'analisi della perplessit&agrave;. I risultati di tali analisi suggeriscono che i soggetti del gruppo SV hanno utilizzato pi&ugrave; parole per indicare uno stesso concetto; mentre i soggetti del gruppo ST hanno utilizzato sempre le stesse parole presenti nello scenario testuale. Le analisi condotte sui due corpora hanno confermato quindi la nostra ipotesi che gli scenari testuali influenzano la scelta del lessico usato per esprimere i concetti dello scenario molto pi&ugrave; degli scenari visivi. Inoltre, le frasi prodotte a partire dagli scenari visivi mostrano una maggiore differenziazione lessicale. Questi risultati possono essere spiegati considerando il ruolo del linguaggio nella cognizione e nella psicologia sociale sottostante agli esperimenti con soggetti umani. Il linguaggio infatti aiuta a segmentare e a categorizzare la realt&agrave;. Avere a disposizione una situazione gi&agrave; linguisticamente descritta risparmia lo sforzo di trovare la segmentazione e la categorizzazione appropriate alla situazione ma al tempo stesso non incoraggia a trovare segmentazioni e categorizzazioni alternative. Inoltre, un esperimento &egrave; un contesto sociale specifico che induce deferenza verso lo sperimentatore da parte del soggetto sperimentale. Per questi motivi, i soggetti esposti a situazioni descritte linguisticamente tendono a usare lo stesso linguaggio usato nel materiale sperimentale che hanno ricevuto. Mentre i soggetti esposti a situazioni visive devono trovare un loro modo per descrivere linguisticamente il materiale visivo loro proposto. Per concludere, i corpora vocali generati con scenari testuali e visivi a partire dalle stesse descrizioni concettuali sono sostanzialmente diversi e possono essere combinati vantaggiosamente in un unico corpus pi&ugrave; ricco per addestrare sistemi di comprensione automatica di languaggio parlato.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<FONT SIZE=4><P ALIGN="JUSTIFY">&nbsp;</P>
</FONT><B><FONT SIZE=5><P ALIGN="CENTER">Il sistema "RES" per il riconoscimento del parlato</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Mauro Falcone</P>
</I></FONT><P ALIGN="CENTER">Speech Communication Group</P>
<P ALIGN="CENTER">Multimedia Communication Department</P>
<P ALIGN="CENTER">Fondazione Ugo Bordoni</P>
<P ALIGN="CENTER">v. B. Castiglione 59 00142 Roma Italy</P>
<P ALIGN="CENTER">tel: + 39 06 54803354; fax: + 39 06 54804405</P>
<P ALIGN="CENTER">e-mail: <A HREF="mailto:cristina@fub.it"><U><FONT FACE="Courier New" SIZE=2 COLOR="#0000ff">falcone@fub.it</U></FONT></A></P>
<FONT FACE="Courier New" SIZE=2><P ALIGN="CENTER"></FONT><A HREF="http://www.fub.it/"><U><FONT FACE="Courier New" SIZE=2 COLOR="#0000ff">http://www.fub.it</U></FONT></A></P>
<FONT SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><P ALIGN="JUSTIFY">Si presenta il sistema RES sviluppato in Fondazione Ugo Bordoni, per il riconoscimento automatico del parlato. Il sistema fa riferimento ad un software di riconoscimento del parlato basato sulla tecnologia dei Modelli Markoviani Nascosti, sviluppato in C++ e che verr&agrave; distribuito in versione aperta, ovvero con codice sorgente in un volume di prossima pubblicazione (<I>C. Becchetti, L. Prina Ricotti "Speech Recognition: Theory and C++ Implementation", John Wiley &amp; Sons</I>).</P>
<P ALIGN="JUSTIFY">Verranno descritti i moduli base del software e le principali filosofie  di implementazione; inoltre sar&agrave; esposto lo schema del riconoscitore ed alcuni esperimenti eseguiti su database tra i pi&ugrave; noti quali TIMIT, ed ATIS.</P>
<B><P ALIGN="JUSTIFY">Le librerie "INTEL" per in Signal Processing e lo Speech Processing</P>
</B><P ALIGN="JUSTIFY"> Nell'ambito della elaborazione del segnale vocale ed in particolare del riconoscimento del parlato diviene sempre pi&ugrave; importante la possibilit&agrave; di effettuare elaborazioni veloci del segnalo parlato su sistemi commerciali standard quali i personal computer su piattaforma Intel. A tal proposito verranno brevemente descritte le librerie distribuite "gratuitamente" dalla Intel per la elaborazione ed il riconoscimento del parlato.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="CENTER">&nbsp;</P><DIR>
<DIR>

<B><FONT SIZE=5><P ALIGN="CENTER">Algoritmi di assessment per un percorso di apprendimento</P>
<P ALIGN="CENTER">personalizzato: il self-access per L2.</P>
</B></FONT><P ALIGN="JUSTIFY"></P>
<I><FONT SIZE=4><P ALIGN="CENTER">Cesare Gagliardi  &amp; Anna Zanfei</P>
</I></FONT><P ALIGN="CENTER">Centro Linguistico di Ateneo</P>
<P ALIGN="CENTER">Universit&agrave; degli Studi di Verona</P>
<P ALIGN="CENTER">Via S.Francesco, 29</P>
<P ALIGN="CENTER">37129 - VERONA</P>
<P ALIGN="CENTER">Tel.:0458009844   Fax: 0458009372</P></DIR>
</DIR>

<P ALIGN="CENTER">E-mail: <A HREF="mailto:azanfei@chiostro.univr.it"><U><FONT FACE="Courier New" SIZE=2 COLOR="#0000ff">azanfei@chiostro.univr.it</U></FONT></A></P>
<P ALIGN="CENTER"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<P ALIGN="JUSTIFY">Per determinare un percorso personalizzato di ICALL (intelligent computer assisted language learning) &egrave; necessario costruire un modello di riferimento e permettere ad un sistema tutoriale intelligente di ricostruire di volta in volta il percorso di apprendimento sulla base di procedimenti algoritmici. Il CLA di Verona &egrave; il luogo in cui si attua un progetto per l'aula multimediale in cui verr&agrave; implementato un sistema di assessment adattivo basato su un modello ricavato da una procedura di interrogazione dei collaboratori ed esperti linguistici che operano nel centro. Al modello di base verranno applicati gli algoritmi di assessment per rendere i test personalizzati ed economici in una parola: adattivi. La procedura di assessment viene in primo luogo utilizzata per testare il modello costruito con la raccolta dei dati ricavati dall'interrogazione degli esperti e l'applicazione di regole matematiche specifiche. L'assessment adattivo deve poi essere testato secondo procedure sperimentali. Il progetto &egrave; assai ampio e in questa fase presentiamo solo il funzionamento degli algoritmi utilizzabili per la "query" degli esperti e l'assessment degli studenti.  </P>
<P ALIGN="JUSTIFY"></P><DIR>
<DIR>

<B><FONT SIZE=4><P ALIGN="JUSTIFY">Bibliografia: </P>
</B></FONT><P ALIGN="JUSTIFY">Koppen M.(1993), "Extracting Human Expertise for Contructing Knowledge Spaces: an algorithm", Journal of Mathematical Psychology 37, 1-20. </P></DIR>
</DIR>

<P ALIGN="JUSTIFY">J.C.Falmagne, J.P.Doignon (1988) "A Markovian Procedure For Assessing The States Of A System", Journal of Mathematical Psychology:32, 232-258.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT FACE="Palatino" SIZE=4><P ALIGN="CENTER">&quot;I cambiamenti dell&#146;italiano radiofonico negli ultimi 50 anni&quot;</P>
<P ALIGN="CENTER">Aspetti segmentali (prima comunicazione) e aspetti ritmico-prosodici (seconda comunicazione)</P>
</B><P ALIGN="CENTER">Massimo Pettorino, Adriana Giannini</P>
<P ALIGN="CENTER">Universit&agrave; di Napoli</P>
</FONT><FONT FACE="Palatino"><P ALIGN="CENTER">E-mail:Massimo Pettorino </FONT><A HREF="mailto:mapettor@unina.it"><U><FONT COLOR="#0000ff">mapettor@unina.it</U></FONT></A></P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&#9;Il parlato dei mass media, radiofonico  e televisivo, viene spesso preso come punto di riferimento  quando si va alla ricerca del cosiddetto italiano &quot;standard&quot;. Tuttavia, come &egrave; ovvio, anche l&#146;italiano standard cambia nel tempo in funzione di fattori di vario tipo. Ma quali sono le variazioni in atto e quali le tendenze di sviluppo per il futuro? Alcuni studi sono stati gia&#146; condotti in tal senso, comparando l&#146;italiano prodotto negli anni &#146;50 con quello di oggi. Tuttavia  in questi lavori  i testi confrontati erano necessariamente diversi. Per superare questa difficolt&agrave;, abbiamo operato un artificio. Alcuni brani tratti da radiogiornali degli anni &#146;50, sono stati trascritti e, in collaborazione con la sede Rai di Napoli, sono stati inseriti tra le notizie di un giornale radio attuale. Lo speaker ha cos&igrave; letto il testo secondo i canoni che quotidianamente segue. Questo materiale &egrave; stato poi analizzato strumentalmente. I risultati  costituiscono l&#146;oggetto delle due comunicazioni qui proposte, una riguarda il piano segmentale, l&#146;altra quello ritmico-prosodico. </P>
<P ALIGN="JUSTIFY">&#9;Nel primo lavoro vengono  rilevate le formanti delle vocali e, per ciascun parlante, viene comparato il sistema tonico con quello atono. E&#146; importante notare che, grazie all&#146;artificio descritto sopra, e&#146; possibile confrontare elementi che occorrono in situazioni contestuali del tutto simili, in quanto il testo, come si e&#146; detto, e&#146; lo stesso e prodotto in una medesima situazione ambientale, ma pronunciato a distanza di circa mezzo secolo. I risultati di tali analisi mostrano le variazioni occorse  in questo intervallo di tempo e indicano la linea di tendenza per il futuro. Il secondo lavoro proposto si sofferma sugli aspetti ritmico-prosodici. Dei due enunciati messi a confronto vengono calcolati gli indici di fluenza, velocita&#146; di eloquio e di articolazione, la distribuzione e durata delle pause e infine l&#146;andamento intonativo.  Un esame  che, se pur condotto su un campione ridotto, rivela aspetti interessanti dei cambiamenti avvenuti nella nostra lingua negli ultimi 50 anni. </P>
<B><FONT SIZE=5><P ALIGN="CENTER">Modelli di predizione prosodica</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Barbara Gili</P>
</I></FONT><P ALIGN="CENTER">Scuola Normale Superiore</P>
<P ALIGN="CENTER">p.zza dei Cavalieri 7</P>
<P ALIGN="CENTER">56126 Pisa</P>
<FONT SIZE=4><P ALIGN="CENTER"></FONT><A HREF="gili@alphalinguistica.sns.it"><U><FONT SIZE=4 COLOR="#0000ff">E-mail: gili@alphalinguistica.sns.it</U></FONT></A></P>
<FONT SIZE=4><P ALIGN="CENTER"></FONT><A HREF="http://alphalinguistica.sns.it/"><U><FONT SIZE=4 COLOR="#0000ff">http://alphalinguistica.sns.it</U></FONT></A></P>
<FONT SIZE=4><P ALIGN="CENTER">&nbsp;</P>
</FONT><P ALIGN="JUSTIFY">La struttura prosodica arricchisce gli enunciati di informazioni di tipo pragmatico, esplicitando, ad esempio, l&#146;intenzione comunicativa del parlante, ma fornisce anche indicazioni utili sulla struttura delle frasi a cui viene associata. Poich&eacute; si &egrave; essenzialmente liberi di scegliere quali variazioni prosodiche realizzare, esiste un alto grado di variabilit&agrave;  nelle relazioni  tra struttura prosodica e struttura di frase. Tuttavia, &egrave; possibile individuare alcune &#145;tipiche&#146; corrispondenze tra prosodia e testo, e pensare, quindi, che le informazioni relative ad una struttura possano gettare luce sull&#146;altra, e viceversa. Tale corrispondenza consente alle tecnologie vocali sia di sfruttare le variazioni  prosodiche per ricavare indicazioni  sulla struttura delle frasi (procedimento utile nei sistemi di riconoscimento vocale), sia di ricavare alcune informazioni prosodiche a partire dall&#146;analisi strutturale degli enunciati (processo caratteristico dei sistemi di sintesi vocale).</P>
<P ALIGN="JUSTIFY">Nel corso dell&#146;intervento, considereremo prevalentemente il secondo aspetto, fornendo una panoramica delle tecniche utilizzate per generare automaticamente la prosodia a partire dal testo. Ci concentreremo, quindi, sui sistemi di sintesi vocale piuttosto che su quelli di riconoscimento, in  cui l'elaborazione prosodica ha avuto fino ad oggi un ruolo secondario. In particolare, prenderemo in considerazione esempi concreti  di sistemi in cui la struttura prosodica viene ricostruita per mezzo di regole, altri  in cui si utilizzano algoritmi di apprendimento automatico, e, infine, sistemi in cui il problema viene, in un certo senso, aggirato concatenando unit&agrave; che siano gi&agrave; caratterizzate prosodicamente. </P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=6><P ALIGN="CENTER">&nbsp;</P>
<P ALIGN="CENTER">Riconoscimento vocale per vocabolari multilingua</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Giorgio Micca</P>
</I><P ALIGN="CENTER">CSELT</P>
<P ALIGN="CENTER">Via G. Reiss Romoli 274</P>
<P ALIGN="CENTER">10148 Torino, Italia</P>
<P ALIGN="CENTER">Tel: +39 011 228 6241</P>
<P ALIGN="CENTER">Fax: +39 011 228 6207</P>
<B><P ALIGN="CENTER"></B></FONT><A HREF="giorgio.micca@cselt.it"><B><U><FONT SIZE=4 COLOR="#0000ff">E-mail: giorgio.micca@cselt.it</B></U></FONT></A></P>
<B><P ALIGN="CENTER"></P>
</B><P ALIGN="JUSTIFY">I riconoscitori vocali per vocabolari flessibili richiedono un modellamento con unita` piu` piccole della parola, a differenza dei riconoscitori specializzati per particolari applicazioni dove l&#146;insieme delle parole chiave e` costituito da poche decine di elementi. In quest&#146;ultimo caso si adotta un modello a parole intere, che ha il pregio di ottimizzare le prestazioni in termini di accuratezza di riconoscimento. Normalmente si definiscono insiemi di alcune centinaia di unita` acustico-fonetiche che fanno riferimento alla struttura fonetica di una data lingua. Tali unita` possono modellare anche gli allofoni, e in genere differenziano un modello fonetico in funzione del contesto in cui tale modello si trova. Si ottengono cosi` i trifoni, dove il fonema e` considerato nel contesto dei fonemi sinistro e destro adiacenti, i polifoni, dove l&#146;orizzonte di dipendenza si estende anche a distanze di ordine due o superiore, i modelli sillabici, dove la coarticolazione e` modellata implicitamente all&#146;interno della sillaba, ed infine i modelli di tipo transizione-stazionarieta`, dove si rappresentano in modo differenziato ed esplicito le componenti stazionarie dei fonemi e le traiettorie di transizione da un fonema a quello immediatamente successivo. Tanto piu` e` dettagliato il modello, tanto maggiore e` la sua precisione di rappresentazione all&#146;interno dello spazio acustico della lingua, ma tanto piu` e` difficile addestrare in modo robusto il modello stesso, perche` la cardinalita` dell&#146;insieme delle unita` aumenta. Ad esempio, per poter garantire una copertura molto elevata di tutti I fenomeni fonotattici della lingua italiana, sarebbe necessario definire un insieme di trifoni di circa sette-ottomila elementi; se si considera che per avere un modello sufficientemente robusto dal punto di vista statistico e` necessario disporre di almeno un centinaio di occorrenze di ogni elemento all&#146;interno della base dati di addestramento, e se si tiene conto che, anche in una base dati lessicalmente progettata in modo tale da risultare foneticamente bilanciata, la distribuzione di frequenza delle unita` presentera` egualmente delle forti asimmetrie dovute alla struttura stessa della lingua, si capisce come un modello trifonico ad alta copertura fonotattica richiederebbe una base dati di dimensioni difficilmente gestibili e troppo costosa. Un modello sillabico avrebbe difficolta` analoghe, ed un modello polifonico ancora maggiori. Normalmente, ci si limita a rappresentare I fenomeni a piu` alta incidenza statistica, cosicche` una data parola verra` rappresentata in definitiva da un insieme misto di unita` di vario grado di contestualita` (ad esempio, trifoni, bifoni destri e sinistri e semplici fonemi). In questo modo, si raggiunge un compromesso tra <I>precisione</I> del modello e sua <I>addestrabilita`.</I> I modelli di tipo transizione-stazionarieta` hanno il vantaggio di generare una minore complessita` dell&#146;insieme di unita` - alcune centinaia &#151; e sono stati recentemente utilizzati nel riconoscimento vocale con buoni risultati. Una ulteriore dimensione viene introdotta quando si considera la multilingualita`, la` dove si intendere sviluppare un modello di riconoscimento tendenzialmente indipendente dalla lingua, o per lo meno utilizzabile con un vocabolario applicativo costituito da parole appartenenti ad un insieme definito di lingue diverse. In questo caso la cardinalita` dell&#146;insieme delle unita` da rappresentare aumenta linearmente con il numero delle lingue interessate.</P>
<P ALIGN="JUSTIFY">Recentemente ho affrontato questo tema di ricerca, cercando di dare una risposta a due quesiti:</P>
<OL>

<P ALIGN="JUSTIFY"><LI>come definire un modello acustico-fonetico multilingua per riconoscitori vocali a vocabolario flessibile adatti ad applicazioni che richiedono la presenza di parole appartenenti a lingue diverse;</LI></P>
<P ALIGN="JUSTIFY"><LI>come sfruttare un modello multilingua di questo tipo per &quot;interpolare&quot; un riconoscitore in una nuova lingua, diversa da quelle del modello originario, tenendo conto delle similarita` fonetiche dei suoni della nuova lingua rispetto ai suoni di una delle lingue del modello multilingua. Quest&#146;ultimo punto ha una variante applicativa interessante, che e` quella di poter sviluppare un riconoscitore statisticamente robusto anche per una lingua per la quale la quantita` di materiale vocale disponibile per l&#146;addestramento e` scarsa, anche qui sfruttando la similarita` dei suoni della lingua considerata con quelli delle N-1 lingue appartenenti al modello.</LI></P></OL>

<P ALIGN="JUSTIFY">L&#146;approccio seguito, ancora in corso di sviluppo, ha due componenti:</P>
<OL TYPE="a">

<P ALIGN="JUSTIFY"><LI>introduzione di metriche &quot;a posteriori&quot; per la misura del grado di similarita` dei modelli acustico-fonetici dei suoni di due o piu` lingue, ottenedo una struttura gerarchica che rappresenta gli aggregamenti in classi in funzione delle metriche adottate;</LI></P>
<P ALIGN="JUSTIFY"><LI>Introduzione dell&#146;unita` acustico-fonetica di base, che` quella di tipo classe di transizione-stazionarieta`, dove pero` vengono effettuati due tipi di accorpamenti: 1) tra elementi di stazionarieta` dove la metrica introdotta al punto a) individua simililarita` superiori ad una soglia prefissata, e 2) tra elementi di classi di transizioni, la` dove la stessa metrica individua elementi cosi` vicini nello spazio acustico da dover essere unificati.</LI></P></OL>

<P ALIGN="JUSTIFY">Se la granularita` delle classi fonetiche e` elevata, come ad esempio avviene in un modello dove si distinguano essenzialmente suoni plosivi, fricativi e liquidi-nasali, piu` le classiche tre classi vocaliche (frontali, centrali e posteriori), il modello risulta sufficientemente generale da non dover richiedere &#151; probabilmente &#151; nessuna unificazione di modelli di transizioni tra le suddette classi, almeno per le principali lingue europee considerate. In questo modo, e` possibile ottenere un modello acustico-fonetico allo stesso tempo semplice &#151; poche centinaia di unita` - e preciso, o almeno ottimale rispetto alla cardinalita` ammissibile dell&#146;insieme. Il modello risultera` tanto piu` generale quanto piu` lingue saranno state considerate in fase di progetto, e anche tanto piu` capace di adattarsi ad una lingua nuova o &quot;povera&quot;, nel senso dato a tale termine in precedenza. Vengono presentati risultati ottenuti nel caso bilingue Italiano e Spagnolo, e si presenta il progetto relativo alla estensione del modello all&#146;Inglese ed al Tedesco, con una possibile sperimentazione alla &quot;interpolazione&quot; di un riconoscitore per il Rumeno.</P>
<FONT FACE="Arial" SIZE=4><P ALIGN="JUSTIFY"></P>
</FONT><B><FONT SIZE=4><P ALIGN="JUSTIFY">Bibliografia</P>
</B></FONT><P ALIGN="JUSTIFY">1) P. Bonaventura, F. Gallocchio, G. Micca, &quot;Multilingual Speech Recognition for Flexible Vocabularies&quot;, EuroSpeech &#146;97, Rodi, Gracia, 22-25 settembre 1997,  pp. 355-358.</P>
<P ALIGN="JUSTIFY">2) P. Bonaventura, F. Gallocchio, J. Mari, G. Micca, &quot;Speech Recognition Methods for Non-Native Pronunciation Variations&quot;, Workshop on &quot;Modeling Pronunciation Variation for Automatic Speech Recognition&quot;, Rolduc, Olanda, 4-6 maggio 1998, pp. 17-22</P>
<P ALIGN="JUSTIFY"></P>
<B><FONT SIZE=5><P ALIGN="CENTER">Gli HMMs nel riconoscimento all'IRST</P>
</FONT><I><P ALIGN="CENTER">Maurizio Omologo</P>
</B></I><P ALIGN="CENTER">ITC-IRST</P>
<P ALIGN="CENTER">Povo - Trento</P>
<FONT SIZE=4><P ALIGN="CENTER"></FONT><A HREF="omologo@irst.itc.it"><U><FONT SIZE=4 COLOR="#0000ff">E-mail: omologo@irst.itc.it</U></FONT></A></P>
<FONT SIZE=4><P ALIGN="CENTER"></FONT><A HREF="http://poseidon.itc.it:6116/~omologo"><U><FONT SIZE=4 COLOR="#0000ff">http://poseidon.itc.it:6116/~omologo</U></FONT></A></P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">Negli ultimi anni i piu' efficaci sistemi per il riconoscimento automatico della voce (ASR) sono basati sui Modelli di Markov nascosti (HMM) e il loro impiego per la modellizzazione acustica del parlato continuo prevale in questo campo. Benche' il paradigma HMM rappresentera' per lungo tempo la tecnologia dominante, presenta comunque degli aspetti critici: la debole modellizzazione della durata, l'assunzione di indipendenza delle osservazioni data una sequenza di stati, le limitazioni di parametri acustici basati sull'analisi a finestre.</P>
<P ALIGN="JUSTIFY">L'efficacia nel trattare l'intrinseca variabilita' del parlato e le buone prestazioni sono spiegabili con la capacita' di gestire sorgenti non-stazionarie ma la teoria non prevede un esplicito meccanismo per modellare le variazioni dei segnali e le corrispondenti relazioni temporali dato un contenuto fonetico fissato. Viene assunta la stazionarita' condizionata dallo stato per i dati osservati e solo la catena di Markov nascosta si "adatta" alla non-stazionarieta' della produzione vocale. Questa ipotesi di stazionarieta' degli stati appare ragionevole se uno stato rappresenta un segmento breve di alcuni suoni (es. fricative) mentre per segmenti piu' lunghi tale assunzione si mostra inadeguata; le regioni di transizione tra fonemi rivelano la dominante natura non stazionaria della voce. Il rilassamento dell'ipotesi di indipendenza condizionata delle osservazioni e' oggetto di numerosi studi. Un semplice meccanismo in uso per considerare questa dipendenzatemporale e' l'aumento dello spazio delle osservazioni acustiche con le derivate dei parametri.  E' anche possibile impiegare parametri segmentali piuttosto che ricavati dall'analisi a finestre ma il modello statistico corrispondente risulta notevolmente piu'  complesso.</P>
<P ALIGN="JUSTIFY"></P>
<B><FONT SIZE=5><P ALIGN="CENTER">Brevi osservazioni in merito ad alcune differenze tra gli schemi intonativi adottati da uno stesso locutore per comunicare in codici linguistici diversi</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Antonio Romano<SUP>1</SUP> &amp; Stefania Roullet<SUP>1 &amp; 2</P>
</I></FONT><P ALIGN="CENTER">1</SUP> Centre de Dialectologie de Grenoble</P>
<P ALIGN="CENTER">Universit&eacute; Stendhal BP 25</P>
<P ALIGN="CENTER">Domaine Universitaire</P>
<P ALIGN="CENTER">38040 Grenoble (France)</P>
<P ALIGN="CENTER"></P>
<SUP><P ALIGN="CENTER">2</SUP> B.R.E.L. - Bureau R&eacute;gional pour l'Ethnologie et la Linguistique</P>
<P ALIGN="CENTER">via Grand Eyvia, 59</P>
<P ALIGN="CENTER">11100 Aosta (Italia)</P>
<P ALIGN="CENTER"></P>
<I><P ALIGN="CENTER">Autore da contattare:</P>
</I><P ALIGN="CENTER">Antonio Romano, e-mail: <A HREF="mailto:romano@u-grenoble3.fr"><U><FONT SIZE=4 COLOR="#0000ff">romano@u-grenoble3.fr</U></FONT></A></P>
<P ALIGN="CENTER">Tel.: +33 4 76 82 68 64 Fax: +33 4 76 82 43 56</P>
<FONT SIZE=4><P ALIGN="CENTER"></P>
</FONT><P ALIGN="JUSTIFY">Con questo intervento vorremmo stimolare la discussione in merito ad alcuni interessanti fenomeni di "interferenza" tra gli elementi prosodici di uno o pi&ugrave; codici linguistici, a cui uno stesso locutore pu&ograve; fare riferimento, pur disponendone con diversi "gradi di sicurezza".</P>
<P ALIGN="JUSTIFY">Da pi&ugrave; parti si sostiene che le caratteristiche prosodiche, in particolar modo intonative, siano le ultime ad essere abbandonate e le prime ad essere acquisite. Secondo D. Hirst &amp; A. Di Cristo (1998, p. 2), ad esempio,  &quot;&nbsp;The prosodic characteristics of a language are not only probably the first phonetic features acquired by a child [...] but also the last to be lost either through aphasia [...] or during the acquistion of another language or dialect&nbsp;&quot;. In ogni caso, sembra che i mutamenti che coinvolgono le strutture ritmiche e intonative siano meno rapidi di quelli che riguardano il lessico e la morfosintassi (cfr. Bertinetto &amp; Magno-Caldognetto, 1993, p. 141). </P>
<P ALIGN="JUSTIFY">Rivolgendoci in particolar modo alle variet&agrave; linguistiche che costituiscono il principale oggetto della nostra attenzione (e cio&egrave; l'italiano e le altre variet&agrave; romanze che con esso convivono) siamo immediatamente messi a confronto con una realt&agrave; in cui tale processo di "acquisizione/obl&igrave;o" mostra un'intensa dinamica, spesso caratterizzata da interazioni tra sistemi diversi piuttosto che da pressioni unilaterali.</P>
<P ALIGN="JUSTIFY">Gi&agrave; G.B. Pellegrini (1960, p. 16) sosteneva che &quot;&nbsp;la pronuncia dell'italiano regionale svela quasi sempre il sottofondo dialettale che fa capolino con maggiore o minore evidenza secondo l'attenzione e la cultura del parlante&nbsp;&quot;. Inoltre, come fa notare T. Telmon (1990, p. 14), &quot;&nbsp;Ci&ograve; che &egrave; assai pi&ugrave; interessante &egrave; che anche oggi, in una situazione di drastica riduzione numerica dei dialettofoni, i fatti intonativi, prosodici e fonologici continuano ad essere le spie acutissime della regionalit&agrave; di qualsiasi parlante italiano&nbsp;&quot;.</P>
<P ALIGN="JUSTIFY">Concentrando la nostra attenzione sui fenomeni prosodici, ci accorgiamo che, come descritto, ad esempio, da M. Voghera (1992, p.&nbsp;88), &quot;&nbsp; [...] &egrave; proprio a livello intonativo che si sedimentano differenze tra parlanti di diversa provenienza geografica e/o culturale&nbsp;&quot;. Dello stesso avviso &egrave; anche L. Canepari (1979, p. 276), che sostiene: &quot;&nbsp;spesso coloro che hanno eliminato le caratteristiche articolatorie (pi&ugrave;) marcatamente regionali della loro pronuncia conservano le strutture intonative della loro parlata originaria: ch&eacute; sono le pi&ugrave; difficili da modificare&nbsp;&quot;.</P>
<P ALIGN="JUSTIFY">Malgrado queste interessanti considerazioni di ordine generale - che un qualsiasi attento ascoltatore pu&ograve; confermare sulla base della sua quotidiana esperienza -, ci sembra che nessuna analisi descrittiva di approccio diretto, sia mai stata rivolta all'analisi dei cambiamenti osservabili nel sistema intonativo di una determinata area linguistica italiana, nel passaggio da un registro all'altro (per es. formale vs. informale), o allo studio di una determinata situazione di dinamiche linguistiche in cui siano coinvolti "due" codici distinti. </P>
<P ALIGN="JUSTIFY">Al tentativo di dare una spiegazione di tale fenomeno potrebbe essere d'aiuto il quadro fornito da A.A. Sobrero &amp; I. Tempesta (1996, p. 110), secondo i quali : &quot;&nbsp;La pressione standardizzante della scuola ha sempre agito sulla fonetica e sul lessico&nbsp;: per pi&ugrave; di un secolo la didattica linguistica dell'Italia unita ha fornito, regione per regione, elenchi di suoni e di parole che non dovevano essere usati perch&eacute; troppo vicini al dialetto. [...] Sul ritmo e sull'intonazione i libri non dicevano nulla [...]. Questi livelli di lingua si sono cos&igrave; tramandati senza particolari censure e si sono preservati al punto che oggi l'usare una determinata cadenza &egrave; il segnale pi&ugrave; forte e sicuro - spesso l'unico - dell'appartenenza a una determinata area o areola linguistica&nbsp;&quot;.</P>
<P ALIGN="JUSTIFY">Resta per&ograve; ancora da stabilire come e quando i caratteri di un dato sistema linguistico di cui il locutore dispone <I>ab ovo </I>si affermano nell'uso di un codice linguistico diverso ("quanto?") o quantomeno avvertito come "altro" dallo stesso locutore, indipendentemente dal fatto che egli sia in grado di esercitare un controllo sulle mutue interferenze, e a prescindere dall'aver appreso i due codici linguistici in egual misura e contemporaneamente o in tempi e modi diversi.</P>
<P ALIGN="JUSTIFY">Come risulta evidente, la questione &egrave; spinosa, ma &egrave; soprattutto resa inavvicinabile dall'estrema variabilit&agrave; delle esperienze individuali del locutore. Nella presente occasione, volendo quindi evitare di far rientrare nelle nostre valutazioni le delicate problematiche dell'acquisizione del linguaggio e dell'apprendimento di una seconda lingua, ci limitiamo a riportare i nostri dati discutendo le nozioni di <U>resistivit&agrave;</U> e di <U>labilit&agrave;</U> delle caratteristiche prosodiche nei casi delle lingue a nostra disposizione in questo primo momento.</P>
<P ALIGN="JUSTIFY">Alla luce dei dati  di cui disponiamo, ci proponiamo di verificare specialmente il grado di persistenza (o di variazione) degli schemi intonativi in relazione al mutamento di codice linguistico.</P>
<P ALIGN="JUSTIFY">Per quel che riguarda l'analisi svolta in Valle d'Aosta, si &egrave; scelto di prendere in considerazione due paesi che, pur appartenendo alla stessa area linguistica, si differenziassero il pi&ugrave; possibile quanto al grado di "esposizione all'italiano".</P>
<P ALIGN="JUSTIFY">Da un primo sommario esame dei dati raccolti, sembrano esistere differenze significative tra gli schemi intonativi dei due codici linguistici e nei due punti considerati.</P>
<P ALIGN="JUSTIFY">Grazie a questi primi dati, integrati dall'esperienza linguistica personale di uno degli autori, sembra quindi possibile poter affermare che schemi intonativi caratteristici delle variet&agrave; francoprovenzali e dell'italiano regionale si estendano su aree linguistiche non coincidenti e che, in generale, quelli dell'italiano regionale siano comuni ad aree pi&ugrave; estese al cui interno sono invece riscontrabili, nelle diverse variet&agrave; francoprovenzali, soluzioni prosodiche (ma anche fonetiche, morfosintattiche ecc.) differenti.</P>
<P ALIGN="JUSTIFY">Per il salentino, invece, una prima descrizione piuttosto approssimativa induce a distinguere due sottosistemi intonativi diffusi rispettivamente in un'area meridionale estrema e in una centro-settentrionale (cfr. anche Romano, 1997); il locutore originario di una di queste due aree utilizza il sistema intonativo della sua area quando si esprime nel suo dialetto e nella maggior parte delle situazioni in cui &egrave; chiamato ad esprimersi in italiano in ambiti familiari o subregionali. L'"italiano" di riferimento al di fuori della sua regione pu&ograve; improvvisamente divenire, in maniera del tutto accidentale, un "italiano" presunto dell'interlocutore o un "italiano" di riferimento di provenienza imprevedibile che ricorda quello da lui usato nella lettura (cfr. Savino &amp; Refice, 1997) o quello appreso in determinati contesti extraregionali. Al di l&agrave; dell'esistenza di fasce geografiche di transizione, sembrerebbe anche possibile che delle preferenze individuali facciano emergere uno dei due sistemi in aree in cui il sistema dominante &egrave; messo in ombra da complicate situazioni di contatto o dal progressivo diffondersi di variet&agrave; di prestigio. </P>
<P ALIGN="JUSTIFY">Un sistema potrebbe essere pi&ugrave; arcaico e l'altro "innovativo". Come spiegare per&ograve; la graduale rinuncia da parte di un'intera comunit&agrave; a un sistema intonativo che si pretende profondamente radicato negli usi linguistici di ogni singolo individuo?</P>
<P ALIGN="JUSTIFY"></P>
<B><P ALIGN="JUSTIFY">Bibliografia</P>
</B><P ALIGN="JUSTIFY">Bertinetto P.M. &amp; Magno Caldognetto E. (1993). "Ritmo e intonazione". In A.A. Sobrero (a cura di), <I>Introduzione all'italiano contemporaneo. Le strutture.</I> Bari, Laterza, 141-192.</P>
<P ALIGN="JUSTIFY">Canepari L. (1979). <I>Introduzione alla fonetica</I>. Torino, Einaudi.</P>
<P ALIGN="JUSTIFY">Hirst D. &amp; Di Cristo A. (in corso di stampa). "A survey of intonation systems". In D.J. Hirst &amp; A. Di Cristo (a cura di), <I>Intonation Systems: a Survey of Twenty Languages</I>, Cambridge Univ. Press.</P>
<P ALIGN="JUSTIFY">Pellegrini G.B. (1960). Tra lingua e dialetto in Italia. <I>Studi mediolatini e volgari</I>, VIII, 137-153 (v. anche Pellegrini G.B., 1975, <I>Saggi di linguistica italiana</I>, Torino, Boringhieri).</P>
<P ALIGN="JUSTIFY">Romano A. (1997). Persistence of prosodic features between dialectal and standard Italian utterances in six sub-varieties of a region of southern Italy (Salento): first assessment of the results of a recognition test and an instrumental analysis, <I>Proc. of Eurospeech '97</I>, 175-178.</P>
<P ALIGN="JUSTIFY">Savino M. &amp; Refice M. (1997). "L'intonazione dell'italiano di Bari nel parlato letto e in quello spontaneo". In F. Cutugno (a cura di), <I>Fonetica e fonologia degli stili dell'italiano parlato. </I>Atti delle VII Giornate di Studio del G.F.S., Esagrafica, Roma, 1997, 79-88.</P>
<P ALIGN="JUSTIFY">Sobrero A.A. &amp; Tempesta I. (1996). La Puglia una e bina. <I>Italiano e Oltre</I>, XI, 2, 107-114.</P>
<P ALIGN="JUSTIFY">Telmon T. (1990). <I>Guida allo studio degli italiani regionali</I>. Dell'Orso, Alessandria.</P>
<P ALIGN="JUSTIFY">Voghera M. (1992). <I>Sintassi e intonazione nell'italiano parlato</I>. Il Mulino, Bologna.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=5><P ALIGN="CENTER">Una tecnica di sintesi vocale specializzata per il dominio lessicale dell&#146;Elenco Abbonati</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Luciano Nebbia, Silvia Quazza, Pier Luigi Salza</P>
</I></FONT><P ALIGN="CENTER">CSELT, Centro Studi E Laboratori Telecomunicazioni </P>
<P ALIGN="CENTER">Via G. Reiss Romoli, 274 - 10148 Torino</P>
<P ALIGN="CENTER">Autore di riferimento: Pier Luigi Salza (<A HREF="mailto:pierluigi.salza@cselt.it"><U><FONT SIZE=4 COLOR="#0000ff">pierluigi.salza@cselt.it</U></FONT></A>)</P>
<B><P ALIGN="CENTER">&#1;<I>Riassunto</P>
</B></I><P ALIGN="JUSTIFY">Si descrive la realizzazione di una versione specializzata di Eloquens<SUP>&reg;</SUP>, il sintetizzatore vocale da testo scritto sviluppato in Cselt, progettata con l&#146;obiettivo di conseguire un sostanziale miglioramento dell&#146;intelligibilit&agrave; e della naturalezza della risposta vocale nel servizio &quot;1412&quot;, il servizio informazioni elenco abbonati Richiesta Numerica, che fornisce automaticamente nominativo e indirizzo dell&#146;abbonato a partire dal numero telefonico. Lo sviluppo di una voce pi&ugrave; naturale dovrebbe rendere il servizio automatico pi&ugrave; accettabile all&#146;utenza, che, abituata ai servizi erogati con voce preregistrata, ha accresciuto le proprie aspettative nei confronti della qualit&agrave; acustica delle risposte vocali. L&#146;obiettivo &egrave; stato conseguito sfruttando le caratteristiche peculiari del dominio applicativo: il sistema &egrave; stato specializzato sul dominio lessicale, per quanto riguarda sia la pronuncia delle parole sia il modo di comporle. Vediamo brevemente come.</P>
<P ALIGN="JUSTIFY">Un sintetizzatore vocale da testo per uso generale, quale &egrave; Eloquens<SUP>&reg;</SUP> standard, deve essere predisposto a trattare qualunque testo di una data lingua. Cos&igrave; la maggior parte della capacit&agrave; del sistema di elaborare il testo &egrave; dedicata ad individuare la struttura sintattica della frase e ad assegnarle la corretta prosodia, mentre le unit&agrave; acustiche sono progettate per coprire tutti i possibili contesti fonetici. Le unit&agrave; che da pi&ugrave; tempo vengono usate in sistemi di questo tipo sono <I>difoni</I> con struttura fonetica uniforme e non contestuali. Il vantaggio principale dei difoni di questo tipo &egrave;  dato dalla copertura offerta su testi qualsiasi, perch&egrave; con un unico rappresentante per ciascuna delle combinazioni di suoni possibili in una data lingua (in genere sull&#146;ordine del migliaio) &egrave; possibile generare qualsiasi messaggio in quella lingua. Inoltre, la voce prodotta con questo tipo di tecnica risulta generalmente di alta intelliggibilit&agrave;. Per contro, l&#146;uso dei difoni comporta due notevoli svantaggi: </P>

<UL>
<FONT FACE="Times New Roman,Times New Roman"><P ALIGN="JUSTIFY"><LI>la voce prodotta, pur risultando altamente intelliggibile, presenta gravi carenze dal punto di vista acustico, in particolare per quanto riguarda la naturalezza del timbro, solitamente caratterizzato da uno sgradevole suono &quot;artificiale&quot; o &quot;robotico&quot;, le cui possibili cause sono: l&#146;eccessiva uniformit&agrave; delle unit&agrave; acustiche registrate originariamente; il procedimento utilizzato per la modifica prosodica, il quale provoca delle rilevanti distorsioni nei casi in cui la &quot;distanza&quot; fra i valori prosodici &quot;target&quot; e quelli intrinseci del segnale presente nella base dati originale &egrave; rilevante;</LI></P>
<P ALIGN="JUSTIFY"><LI>cambiando lingua occorre riprogettare <I>ex novo</I> la base dati dei difoni, in conformit&agrave; alle regole fonotattiche  della nuova lingua.</LI></P></UL>

</FONT><P ALIGN="JUSTIFY">Tuttavia, importanti applicazioni della sintesi da testo non traggono beneficio da una impostazione cos&igrave; generale. Ad esempio, nel servizio Richiesta Numerica la struttura del messaggio &egrave; fissa, essendo sostanzialmente composta da una lista di pochi elementi (il nome, il cognome e l&#146;indirizzo), e i contorni prosodici sono semplici e ripetitivi. Data la finalit&agrave; del servizio e la struttura semplice del messaggio, &egrave; stato valutato che la lettura parola per parola sia una modalit&agrave; accettabile (se non addirittura preferibile) di fornire l&#146;informazione. Inoltre, il dominio lessicale &egrave; limitato alle sole parole contenute nell&#146;elenco abbonati. E&#146; stata anzi individuata una lista limitata di parole che da sole coprono un&#146;alta percentuale prefissata delle parole da sintetizzare. Queste caratteristiche dell&#146;applicazione hanno suggerito un approccio alla tecnica di sintesi nel quale il concetto di difono viene profondamente rivisto. Tale approccio punta alla riduzione delle discontinuit&agrave; ai confini di unit&agrave; e delle distorsioni in fase di concatenazione, utilizzando unit&agrave; acustiche <I>non uniformi</I>, cio&egrave; di lunghezza fonetica variabile e comunque pi&ugrave; ampia del difono, e <I>contestuali</I>, cio&egrave; presenti con pi&ugrave; occorrenze prosodicamente differenti. </P>
<P ALIGN="JUSTIFY">Se dovessero essere utilizzate per sintetizzare testi qualsiasi e a struttura sintattica variabile, il numero di tali unit&agrave; acustiche potrebbe risultare enormemente elevato; tuttavia il loro numero si ridimensiona notevolmente se la copertura si deve invece limitare alle parole di un determinato dominio. Inoltre, la lettura a parole isolate semplifica ulteriormente i problemi: da un lato, infatti, riduce fortemente il numero delle unit&agrave; necessarie, essendo escluse quelle ai confini di parola; d&#146;altro lato, il modello prosodico per una data unit&agrave; acustica risulta altamente predicibile sulla base della sua posizione all&#146;interno della parola, ci&ograve; che consente di contestualizzare efficacemente le unit&agrave; mediante una semplice classificazione posizionale e accentuale, in grado gi&agrave; di per s&egrave; di riflettere la struttura sillabica e prosodica della parola isolata. E&#146; diventato cos&igrave; possibile, dalla registrazione di parole lette isolatamente con prosodia il pi&ugrave; possibile uniforme, scegliere le unit&agrave; contestuali che possono essere semplicemente concatenate, senza ulteriori aggiustamenti prosodici. </P>
<P ALIGN="JUSTIFY">La scelta delle unit&agrave; avviene escludendo innnanzi tutto di segmentare le vocali. In secondo luogo, si sono definiti due livelli gerarchici di segmentazione, basati su criteri acustici e percettivi, detti primo livello (o livello ottimo) e secondo livello (o livello sub-ottimo), che si differenziano in base alla &quot;resistenza&quot; alle discontinuit&agrave; coarticolatorie offerta dalle consonanti segmentate. Si &egrave; stabilita quindi una gerarchia delle unit&agrave; da coprire ai due livelli in base alla loro occorrenza in parole pi&ugrave; o meno frequenti. Il dato della frequenza &egrave; stato ricavato dall&#146;analisi statistica di un ampio corpus di cognomi, nomi, indirizzi e parole comuni, inclusi anche parole e cognomi stranieri.  Per unit&agrave; al di fuori di questa copertura  (che in ogni caso ammontano a meno del 4% del totale), si ricorre ai difoni, che rappresentano la soluzione di recupero del sistema. La realizzazione di questo approccio si &egrave; avvalsa della struttura flessibile del sintetizzatore Eloquens<SUP>&reg;</SUP>, che ha reso possibile integrare dunque 3 tipi di unit&agrave; acustiche diverse (primo livello, secondo livello e difoni) per un totale di circa 21.200 segmenti acustici fisicamente conservati nel dizionario (primo livello pi&ugrave; difoni), dai quali si ricavano ancora ulteriori 20.000 sottosegmenti di secondo livello, contenuti nei primi. Sottoposta a valutazione soggettiva, la versione specializzata di Eloquens<SUP>&reg; </SUP>mostra, rispetto a quella standard, un incremento della comprensione soggettiva del 7.6 % nel campo Nome, un incremento di 0.7 punti su 5 della media MOS, un miglioramento dell&#146;intelligibilit&agrave; reale del 4.2% riferito alla parola singola nel campo Nome.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=5><P ALIGN="CENTER">Su alcuni rapporti tra riduzione segmentale e struttura soprasegmentale nel parlato spontaneo.</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Renata Savy</P>
</I></FONT><P ALIGN="CENTER">CIRASS - Centro Interdipartimentale di Ricerca per l'Analisi e la Sintesi</P>
<P ALIGN="CENTER">dei Segnali.</P>
<P ALIGN="CENTER">tel  +39 81 5420281  fax +39 81 5420370</P>
<P ALIGN="CENTER">Universit&agrave; degli Studi di Napoli Federico II</P>
<P ALIGN="CENTER">via Porta di Massa 1 80133 Napoli</P>
<P ALIGN="CENTER">E-mail: <A HREF="mailto:rensavy@unina.it"><U><FONT SIZE=4 COLOR="#0000ff">rensavy@unina.it</U></FONT></A></P>
<P ALIGN="JUSTIFY">Il lavoro che si intende presentare &egrave; parte di una pi&ugrave; ampia ricerca su fenomeni di riduzione e/o cancellazione di materiale fonico segmentale nell&#146;italiano parlato spontaneo. </P>
<P ALIGN="JUSTIFY">L&#146;indagine si basa su un <I>corpus </I>di parlato conversazionale selezionato tra le registrazioni del LIP (cfr. De Mauro et al. 1993) e orientato su due diverse variet&agrave; diatopiche: si tratta di quattro conversazioni spontanee bidirezionali (faccia a faccia), due registrate a Napoli e due a Milano.</P>
<P ALIGN="JUSTIFY">Su questo campione sono state svolte precedentemente alcune indagini incentrate sulle realizzazioni foniche dei suffissi morfologici flessivi dei costituenti nominali e verbali. L&#146;analisi spettroacustica del materiale ha evidenziato che in misura significativa (oltre il 50%) i suffissi flessivi sono soggetti a riduzione; la riduzione si manifesta come a) riduzione timbrica delle vocali finali di parola, b) sostituzione timbrica di vocali finali di parola, c) cancellazione di vocali finali di parola, d) cancellazione di sillabe finali di parola.</P>
<P ALIGN="JUSTIFY">Ulteriori analisi sono state effettuate sul corpus allo scopo di indagare i rapporti che intercorrono tra riduzioni sul versante segmentale e organizzazione prosodica delle stringhe. Il lavoro comprende: </P><DIR>

<P ALIGN="JUSTIFY">1) la segmentazione dei brani di conversazione in unit&agrave; tonali (<B>TU</B>) e costituenti prosodici minori (sintagmi intermedi [<B>SI</B>]);</P>
<P ALIGN="JUSTIFY">2) la classificazione dei contorni melodici e l&#146;individuazione dei <I>pitch accents</I> all&#146;interno delle unit&agrave; prosodiche;</P>
<P ALIGN="JUSTIFY">3) un&#146;analisi distribuzionale delle riduzioni di ordine morfologico-segmentale all&#146;interno delle unit&agrave; intonazionali individuate.</P></DIR>

<P ALIGN="JUSTIFY">Il risultato delle analisi mostra che esiste una correlazione tra la frequenza di riduzione e la <U>posizione</U> di un determinato elemento (o gruppo di elementi) dentro la stringa prosodica. </P>
<P ALIGN="JUSTIFY">In particolare sembra che si possano identificare luoghi della TU particolarmente soggetti ad accogliere fenomeni di riduzione delle strutture sillabiche e della timbrica vocalica e luoghi in qualche modo &#145;protetti&#146; rispetto a tale processo. Questa suddivisione &egrave; correlata da un lato ad un puro fattore posizionale, dall&#146;altro alll&#146;intero schema accentuale dell&#146;unit&agrave;.</P>
<P ALIGN="JUSTIFY">In questa comunicazione verranno analizzate, esemplificate e discusse alcune condizioni prosodiche che favoriscono o inibiscono la riduzione segmentale; le prime presentano come caratteristica comune la presenza di una prominenza accentuale immediatamente prima della sede del fenomeno di riduzione. </P>
<P ALIGN="JUSTIFY">In altre parole, si intende dimostrare che la riduzione sul piano segmentale &egrave; pi&ugrave; probabile e pi&ugrave; frequente in posizione seguente un <I>pitch accent</I>, mentre risulta in qualche modo bloccata nelle posizioni precedenti un <I>pitch accent</I>.</P>
<P ALIGN="JUSTIFY">Verr&agrave; proposta, infine, un&#146;interpretazione del rapporto tra distribuzione delle riduzioni segmentali e schema accentuale nei termini di un principio fisiologico sottostante, alla base della produzione di ciascuna unit&agrave; intonazionale: in stretta connessione con il meccanismo della respirazione, ogni unit&agrave; viene prodotta attraverso una fase di <I>impostazione</I> seguita da una fase di <I>declinazione modulata</I>. </P>
<P ALIGN="JUSTIFY">Tutto ci&ograve; che avviene nella fase di impostazione fino alla segnalazione di una prominenza &egrave; preservato dai fenomeni di riduzione che si verificano, invece, con il rilassamento della tensione necessaria alla produzione, dopo la prominenza (e sul finire della stringa).</P>
<P ALIGN="JUSTIFY">L&#146;intero processo sembra pertanto governato da una &#145;legge del minimo sforzo&#146; articolatorio, violata solo in concomitanza con le parti che vengono poste in rilievo.</P>
<P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=5><P ALIGN="CENTER">Verso un dimensionamento consonantico-temporale dell'italiano sardo-campidanese.</P>
</B></FONT><I><FONT SIZE=4><P ALIGN="CENTER">Dr. Carlo Schirru</P>
</I></FONT><P ALIGN="CENTER">Dipartimento di Linguistica</P>
<P ALIGN="CENTER">Universita' di Padova Via B. Pellegrino 1                                 </P>
<P ALIGN="CENTER">Tel.+  39 49-827 49 11</P>
<P ALIGN="CENTER"> Fax:39 49-827 4919</P>
<P ALIGN="CENTER">35137 PADOVA (ITALY)                    </P>
<P ALIGN="CENTER">E-mail: <A HREF="mailto:schirrc@maldura.unipd.it"><U><FONT SIZE=4 COLOR="#0000ff">schirrc@maldura.unipd.it</U></FONT></A></P>
<FONT SIZE=4><P ALIGN="CENTER"></P>
<B><P ALIGN="JUSTIFY">Abstract</P>
</B><P ALIGN="JUSTIFY">A seguito di uno studio pilota sul vocalismo dell'area campidanese della Sardegna , si intende qui portare un primo parziale contributo allo studio sperimentale del consonantismo corrispondente. Riferita all'aspetto temporale, l'analisi intende focalizzare alcune fra le caratteristiche peculiari espresse dalla variante in oggetto, relativamente a tre localit&agrave; site rispettivamente al centro, al nord e al sud di una fascia mediana dello stesso Campidano. Costituito da una serie di registrazioni-intervista - tesa a massimizzare il grado di naturalezza e omogeneit&agrave; - il corpus contiene le dichiarazioni delle proprie generalit&agrave; da parte di locutori diversificati in funzione dell'et&agrave;, del sesso e del grado di scolarizzazione. Il tutto, in funzione di vari campi applicativi quali il linguistico, l'industriale, il forense, il medico.</P>
</FONT><P ALIGN="JUSTIFY"></P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<P ALIGN="JUSTIFY">&nbsp;</P>
<B><FONT SIZE=5><P ALIGN="CENTER">Progetto per la sperimentazione di un tutor computerizzato per</P>
<P ALIGN="CENTER">l'apprendimento della prosodia dell'inglese per  italofoni: il modulo</P>
<P ALIGN="CENTER">prosodico dello SLIM di Venezia</B></FONT><FONT SIZE=2>.</P>

</FONT><I><FONT SIZE=4><P ALIGN="CENTER">Anna Zanfei &amp; Cesare Gagliardi </P><DIR>
<DIR>

</I></FONT><P ALIGN="CENTER">Centro Linguistico di Ateneo</P>
<P ALIGN="CENTER">Universit&agrave; degli Studi di Verona</P>
<P ALIGN="CENTER">Via S.Francesco, 29</P>
<P ALIGN="CENTER">37129 - VERONA</P>
<P ALIGN="CENTER">Tel.:0458009844   Fax: 0458009372</P></DIR>
</DIR>

<P ALIGN="CENTER">E-mail: <A HREF="mailto:azanfei@chiostro.univr.it"><U><FONT FACE="Courier New" SIZE=2 COLOR="#0000ff">azanfei@chiostro.univr.it</U></FONT></A></P>
<P ALIGN="CENTER"></P>
<FONT FACE="Courier New" SIZE=2><P>&nbsp;</P>
</FONT><P ALIGN="JUSTIFY">La metodologia della ricerca in linguistica applicata si avvale oggi di metodi qualitativi e quantitativi. Cionostante la letteratura in merito a metodi e strumenti di misurazione accreditati &egrave; molto pi&ugrave; solida dal lato quantitativo. La sperimentazione non pu&ograve; quindi non partire da questi strumenti. In questo intervento vengono perci&ograve; presentare le procedure e i metodi utilizzabili, con la costruzione di test adeguati, per la sperimentazione del sistema di riconoscimento del il modulo prosodico dello SLIM di Venezia che mira a sviluppare la prosodia dell'inglese come L2 per studenti adulti. La sperimentazione sar&agrave; attuata secondo questo progetto presso il Centro Linguistico di Ateneo dell'universit&agrave; di Verona. Il metodo scelto &egrave; uno dei pi&ugrave; classici della metodologia quantitativa mentre il pre-test e il post-test sono assolutamente originali. I risultati di questa indagine verranno pubblicati in seguito. Del modulo prosodico preso in considerazione non esistono antecendenti nella formazione assistita da computer: in Italia oggi questi strumenti sono i primi ad avere un'applicazione didattica ed in particolare nella formazione linguistica autonoma di italofoni sono da considersi un prototipo di riferimento. Infine la sperimentazione riveler&agrave; se l'utilizzo di un sistema di tutoraggio automatico per la prosodia cos&igrave; come &egrave; stato concepito e realizzato all'interno dello SLIM abbia un effettivo ed efficace riscontro nell'iter dell'italofono che apprende l'inglese come seconda lingua. La percezione e la produzione della prosodia dell'inglese parlato nello SLIM &egrave; affrontata tramite attivit&agrave; di apprendimento a livello interno della parola e attivit&agrave; a livello di frase fonologica. Il riconoscimento degli enunciati dello studente che imita una voce master fornisce un feedback che permette all'utente di visualizzare istantaneamente dove e in quale misura la lunghezza dei foni emessi dalla voce master differisce dai propri. La visualizzazione della propria performance dovrebbe essere di aiuto per un'immediata valutazione della stessa che permette all'utente di organizzare mentalmente l'intensit&agrave; e la lunghezza con cui emettere i suoni che compongono una parola e una strategia nel caso di una frase di riferimento. I risultati potrebbero indicare in particolare per gli italofoni quali aiuti si rivelano pi&ugrave; efficaci e se sviluppare ulteriormente il modulo prosodico. La pratica operativa rimane comunque un ambiente creativo anche se basato sulla falsariga di una metodologia gi&agrave; data e per questo motivo la sperimentazione sul campo ha sempre un valore significativo sia per le problematiche poste nell'attuazione del progetto che per i risultati attesi o disattesi che siano. La parte dell'indagine qualitativa invece sar&agrave; svolta in un secondo momento non perch&eacute; considerata di minore importanza ma piuttosto per una ragione di tempi di elaborazione e di costruzione del progetto relativo.</P>
<FONT FACE="Courier New" SIZE=2><P ALIGN="JUSTIFY"></P>
</FONT><FONT SIZE=5><P ALIGN="CENTER">Dinamiche Articolatorie nella Produzione Verbale Fluente di Normoparlanti e Balbuzienti</P>
</FONT><I><FONT SIZE=4><P ALIGN="CENTER">Claudio Zmarich</P>
</I></FONT><P ALIGN="CENTER">Istituto di Fonetica e Dialettologia &#151; C.N.R.</P>
<P ALIGN="CENTER">Via G. Anghinoni, 10 - 35121 Padova (ITALY)</P>
<P ALIGN="CENTER">e-mail: <A HREF="mailto:Magno@csrf.pd.cnr.it"><U><FONT SIZE=3 COLOR="#0000ff"> zmarich@csrf.pd.cnr.it</U></FONT></A></P>
<P ALIGN="CENTER">www: <A HREF="http://www.csrf.pd.cnr.it/"><U><FONT SIZE=3 COLOR="#0000ff">http://www.csrf.pd.cnr.it</U></FONT></A></P>
<FONT SIZE=4><P ALIGN="JUSTIFY">&nbsp;</P>
<P ALIGN="JUSTIFY">&#9;</FONT>Per descrivere, valutare, diagnosticare e riabilitare varie patologie articolatorie &egrave; fondamentale disporre di dati di analisi qualitativi e quantitativi, affidabili ed esaustivi, dei movimenti degli organi articolatori, in termini di spostamento, durata, velocit&agrave; e accelerazione. Questi dati permettono di controllare e integrare i tradizionali metodi di descrizione, e cio&egrave; la trascrizione fonetica su base uditivo-percettiva e l'analisi elettroacustica, le cui limitazioni risiedono rispettivamente nella soggettivit&agrave; della valutazione del percetto uditivo e nell&#146;assenza di biunivocit&agrave; tra dato acustico e dato articolatorio. </P>
<P ALIGN="JUSTIFY">&#9;Le limitazioni della trascrizione fonetica e dell'analisi elettroacustica risultano ancor pi&ugrave; evidenti in quei casi in cui un parlato "fluente" dal punto di vista percettivo viene invece prodotto con movimenti articolatori parzialmente o del tutto anomali. E' questo un caso non infrequente con i soggetti balbuzienti: alcuni di loro non presentano le ripetizioni di parte di parola e i prolungamenti di suono che sono considerati tradizionalmente i sintomi della balbuzie, ma avvertono spesso sensazioni di "sforzo" muscolare e tensione cognitiva che difficilmente sono colti dall&#146;osservatore. Se con disordine della fluenza o balbuzie definiamo un quadro sintomatologico in cui viene a mancare o &egrave; ridotta la capacit&agrave; di produrre enunciati privi di discontinuit&agrave; in modo rapido e senza sforzo, allora anche queste persone dovrebbero essere considerate balbuzienti. Inoltre lo studio della produzione verbale percettivamente fluente dei balbuzienti ha un notevole significato teorico, non solo per i clinici ma anche per i fonetisti, perch&eacute; lo sforzo di chiarire  la natura della loro fluenza porterebbe ad approfondire la riflessione sul concetto di &quot;fluenza&quot; dei normoparlanti. Lo studio della balbuzie fluente &egrave; poi importante perch&egrave; permette di isolare i sintomi legati direttamente alla menomazione (sintomi primari) dai sintomi che invece indicherebbero un comportamento di reazione o compensazione della menomazione (sintomi secondari). </P>
<P ALIGN="JUSTIFY">Il problema pricipale insito in tale tipo di ricerca e&#146; per&ograve; rappresentato dalla grande capacit&agrave; compensativa esibita dalle strutture articolatorie in condizioni normali, che rende difficile distinguere la normalit&agrave; dalla patologia. Ci&ograve; &egrave; ben riassunto da Folkins (1991), che a proposito della produzione verbale normale invita a tenere presenti le compensazioni definite "flessibili" e quelle definite "plastiche". Le prime consentono il ricorso a diverse alternative strutturate all'interno di un dato sistema in equilibrio per gestire contesti fonetici di tipo diverso, e fenomeni quali l'accento, l'intonazione, la velocit&agrave; di esecuzione ecc. Le seconde vengono utilizzate in presenza di perturbazioni dell'equilibrio del sistema esistente per raggiungere un nuovo stato di equilibrio (ad es., in situazioni quali parlare mentre si mangia, con la sigaretta tra le labbra, mentre si sta correndo ecc.). A questo proposito Folkins invita a ricordare che "<I>processi inusuali in una parte o livello del sistema possono produrre compensazioni sia plastiche che flessibili in altre parti o livelli. Solamente quando si superano i limiti di plasticit&agrave; e flessibilit&agrave; dell'intero sistema i processi inusuali compromettono l'output comportamentale. Non possiamo definire la fisiologia atipica come patologica finch&eacute; non abbiamo esaminato i limiti di flessibilit&agrave; e plasticit&agrave; per comprendere come i livelli fisiologici interagiscono per produrre l'output comportamentale indesiderato</I>". </P>
<P ALIGN="JUSTIFY">In questa linea di ricerca diventa importantissima l&#146;identificazione delle strategie del controllo motorio. La parola strategia si riferisce ad una regolazione preferenziale di parametri attraverso cui &egrave; possibile manipolare caratteristiche dei singoli movimenti, come la velocit&agrave; di spostamento ecc. Tali strategie di controllo possono essere adottate, all'interno di una pi&ugrave; vasta organizzazione neuro-muscolare e attraverso un apprendimento di tipo subconsciente, utilizzando sinergie funzionali che riducono i gradi di libert&agrave; del sistema motorio per la produzione del parlato, poich&egrave; vincolano reciprocamente i movimenti articolatori individuali in strutture coordinative o gesti.  In questo modo ogni individuo pu&ograve; acquisire un pattern di coordinazione motoria stabile di fronte a variazioni nell'ampiezza, nella durata o nella velocit&agrave; dei movimenti. Questo modello di organizzazione motoria, conosciuta come <I>Task Dynamic model</I> (Saltzman e Munhall, 1989), e, nella sua versione pi&ugrave; fonologica, come "fonologia articolatoria" (Browman &amp; Goldstein, 1986, 1996) si oppone all'impostazione pi&ugrave; classica, in cui gli articolatori sono controllati in modo individuale e indipendente.</P>
<P ALIGN="JUSTIFY">In questi anni pi&ugrave; recenti, gli studi sulla balbuzie di tipo eziologico si sono progressivamente concentrati sul livello fisiologico della menomazione. Quasi tutti gli studi che hanno trattao l&#146;argomento hanno trovato differenze significative tra il comportamento motorio dei b/i e quello dei normoparlanti. Di questi sforzi sono testimonianza le tre conferenze internazionali organizzate dall'Universit&agrave; di Nijmegen (Olanda) nel 1985, nel 1990 e nel 1996. Quest&#146;approccio fornisce una chiave privilegiata di comprensione unitaria di quel fenomeno multidimensionale che &egrave; la balbuzie, che appare condizionata da variabili di natura socioculturale, psicologica, genetica, fisiologica etc. Questa disperante variet&agrave; pu&ograve; essere utilmente semplificata con la considerazione che, per ricoprire un certo ruolo causale nella balbuzie, ciascuna di queste variabili deve alla fine influenzare direttamente o indirettamente i processi del controllo motorio del sistema pneumo-fono-articolatorio.</P>
<P ALIGN="JUSTIFY">In questo studio saranno presentati alcuni indici di natura cinematica e dinamica che permetterebbero di differenziare in modo non banale la produzione verbale fluente dei balbuzienti da quella dei normoparlanti. Una particolare enfasi verr&agrave; portata sui risultati di un esperimento condotto con la strumentazione ELITE da Zmarich e Magno Caldognetto (1995), che partendo dalla considerazione che la presenza di profili di velocit&agrave; (del gesto articolatorio di apertura o chiusura bilabiale) con un unico picco pu&ograve; essere un indice di normalit&agrave; per la coordinazione di sistemi articolatori complessi, hanno scoperto che i balbuzienti esibivano una percentuale molto maggiore di curve di velocit&agrave; irregolari (perche&#146; dotate di picchi multipli) rispetto ai non balbuzienti. Questi risultati sono stati spiegati ricorrendo all&#146;ipotesi che i balbuzienti fanno un uso pi&ugrave; intenso e continuo di un meccanismo di feedback articolatorio inusuale, quello propiocettivo-cinestetico (poich&egrave; le curve di velocit&agrave; con pi&ugrave; picchi riflettono una sequenza di submovimenti usati per effettuare adeguamenti spaziali e temporali durante il movimento principale), probabilmente a causa di un deficit nella fase pianificatrice della parametrizzazione ottimale della forza muscolare.</P>
<FONT SIZE=4><P ALIGN="JUSTIFY"></P>
<B><P ALIGN="JUSTIFY">Bibliografia</P>
</B></FONT><P ALIGN="JUSTIFY">Folkins J.W.: "Stuttering from a speech motor perspective". In H.F.M., Peters, W, Hulstijn, &amp; C.W., Starkweather, (Eds.), <I>Speech motor control  and stuttering</I>,  Excerpta Medica-Elsevier, Amsterdam, 1991, 561- 579.</P>
<P ALIGN="JUSTIFY">Zmarich C. e Magno Caldognetto E., &quot;Analysis of lips and jaw multi-peaked velocity curve profiles in the fluent speech of stutterers and nonstutterers&quot;, in W. Hulstijn, H. Peters and P. Van Lieshout (Eds.), <I>Speech Production: Motor Control, Brain Research and Fluency Disorders&quot;</I>, Elsevier Science, Amsterdam,1997, 177-182.</P></BODY>
</HTML>
